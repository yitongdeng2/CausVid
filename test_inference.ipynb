{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1349a2ed-4eb4-4097-8b5d-f825b1899814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.set_grad_enabled(mode=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.utils import export_to_video\n",
    "from causvid.data import TextDataset\n",
    "from omegaconf import OmegaConf\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62875dec-f69d-4612-9bfb-27d706278967",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"first_test\"\n",
    "logs_dir = os.path.join(\"logs\", exp_name)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "config_path = \"configs/wan_causal_dmd.yaml\"\n",
    "config = OmegaConf.load(config_path)\n",
    "checkpoint_folder = os.path.join(\"checkpoints\", \"autoregressive_checkpoint\")\n",
    "output_folder = logs_dir \n",
    "prompt_file_path = os.path.join(\"prompt_files\", \"prompt1.txt\")\n",
    "prompt_dataset = TextDataset(prompt_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a146f0ea-b03b-4371-9156-94d198c41119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare generator\n",
    "from causvid.models.wan.wan_wrapper import CausalWanDiffusionWrapper\n",
    "generator = CausalWanDiffusionWrapper() # this loads the base \"wan_models/Wan2.1-T2V-1.3B/\" model\n",
    "causvid_state_dict = torch.load(os.path.join(checkpoint_folder, \"model.pt\"), map_location=device)['generator'] # this loads causvid model\n",
    "generator.load_state_dict(causvid_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f6bc478-9321-418c-98e7-bc2f7298053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare text encoder\n",
    "from causvid.models.wan.wan_wrapper import WanTextEncoder\n",
    "text_encoder = WanTextEncoder() # default text encoder, in CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5a63db-f0fe-4077-85c3-a20f20bb4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare vae\n",
    "from causvid.models.wan.wan_wrapper import WanVAEWrapper\n",
    "vae = WanVAEWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a38f1cf3-fa1c-47ea-b066-7d458fce54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VACE\n",
    "import VACE_essentials.vace_wan_model\n",
    "importlib.reload(VACE_essentials.vace_wan_model)\n",
    "from VACE_essentials.vace_wan_model import VaceWanModel\n",
    "vace_ckpt = os.path.join(\"VACE_essentials\", \"vace_wan_models\", \"Wan2.1-VACE-1.3B\")\n",
    "vace = VaceWanModel.from_pretrained(vace_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21ac333d-5da2-4a89-b604-c4222c6097c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KV inference with 3 frames per block\n"
     ]
    }
   ],
   "source": [
    "import causvid.models.wan.my_inference\n",
    "importlib.reload(causvid.models.wan.my_inference)\n",
    "from causvid.models.wan.my_inference import MyInferencePipeline\n",
    "\n",
    "my_pipeline = MyInferencePipeline(generator=generator,\n",
    "                                  text_encoder=text_encoder,\n",
    "                                  vae=vae,\n",
    "                                  args=config, dtype=torch.bfloat16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a943a891-3589-4f03-819f-c8eab095a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c1f4f4887c444d9f2b694b0650028f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled_noise = torch.randn(\n",
    "    [1, 21, 16, 60, 104], device=device, dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "for prompt_index in tqdm(range(len(prompt_dataset))):\n",
    "    prompts = [prompt_dataset[prompt_index]]\n",
    "\n",
    "    video = my_pipeline.inference(\n",
    "        noise=sampled_noise,\n",
    "        text_prompts=prompts\n",
    "    )[0].permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "    export_to_video(\n",
    "        video, os.path.join(output_folder, f\"my_output_{prompt_index:03d}.mp4\"), fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "53d5ac30-401d-4b71-8fff-1ba95bee6c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VaceCausalWanModel were not initialized from the model checkpoint at wan_models/Wan2.1-T2V-1.3B/ and are newly initialized: ['vace_blocks.4.cross_attn.norm_q.weight', 'vace_blocks.8.cross_attn.k.weight', 'vace_blocks.8.self_attn.norm_k.weight', 'vace_blocks.4.cross_attn.o.weight', 'vace_blocks.1.cross_attn.v.weight', 'vace_blocks.9.cross_attn.o.weight', 'vace_blocks.0.self_attn.norm_q.weight', 'vace_blocks.12.cross_attn.k.bias', 'vace_blocks.1.self_attn.o.weight', 'vace_blocks.10.modulation', 'vace_blocks.10.cross_attn.q.bias', 'vace_blocks.5.self_attn.k.bias', 'vace_blocks.5.cross_attn.norm_q.weight', 'vace_blocks.12.cross_attn.norm_k.weight', 'vace_blocks.7.cross_attn.k.weight', 'vace_blocks.13.cross_attn.q.bias', 'vace_blocks.11.self_attn.k.bias', 'vace_blocks.11.cross_attn.norm_q.weight', 'vace_blocks.11.ffn.0.weight', 'vace_blocks.14.self_attn.v.weight', 'vace_blocks.13.cross_attn.v.bias', 'vace_blocks.8.cross_attn.v.weight', 'vace_blocks.7.self_attn.k.weight', 'vace_blocks.13.norm3.weight', 'vace_blocks.8.self_attn.v.weight', 'vace_blocks.10.cross_attn.o.weight', 'vace_blocks.8.cross_attn.norm_q.weight', 'vace_blocks.3.self_attn.q.bias', 'vace_blocks.3.norm3.weight', 'vace_blocks.5.cross_attn.v.bias', 'vace_blocks.1.self_attn.norm_q.weight', 'vace_blocks.1.cross_attn.k.weight', 'vace_blocks.6.norm3.bias', 'vace_blocks.13.cross_attn.k.weight', 'vace_blocks.1.cross_attn.o.bias', 'vace_blocks.6.self_attn.v.bias', 'vace_blocks.1.cross_attn.k.bias', 'vace_blocks.6.cross_attn.norm_k.weight', 'vace_blocks.2.self_attn.q.weight', 'vace_blocks.2.self_attn.k.bias', 'vace_blocks.12.self_attn.k.weight', 'vace_blocks.12.cross_attn.norm_q.weight', 'vace_blocks.5.self_attn.o.bias', 'vace_blocks.2.ffn.2.bias', 'vace_blocks.11.self_attn.o.weight', 'vace_blocks.0.ffn.2.weight', 'vace_blocks.12.cross_attn.q.weight', 'vace_blocks.12.cross_attn.k.weight', 'vace_blocks.1.ffn.0.weight', 'vace_blocks.10.norm3.bias', 'vace_blocks.4.self_attn.k.bias', 'vace_blocks.9.self_attn.q.bias', 'vace_blocks.14.cross_attn.norm_q.weight', 'vace_blocks.5.norm3.bias', 'vace_blocks.2.norm3.bias', 'vace_blocks.14.norm3.bias', 'vace_blocks.11.cross_attn.q.weight', 'vace_blocks.12.cross_attn.q.bias', 'vace_blocks.1.self_attn.q.weight', 'vace_blocks.14.after_proj.weight', 'vace_blocks.2.self_attn.o.bias', 'vace_blocks.9.cross_attn.q.bias', 'vace_blocks.3.after_proj.bias', 'vace_blocks.8.ffn.0.weight', 'vace_blocks.4.self_attn.norm_q.weight', 'vace_blocks.4.self_attn.v.weight', 'vace_blocks.3.cross_attn.k.weight', 'vace_blocks.11.ffn.2.bias', 'vace_blocks.5.cross_attn.norm_k.weight', 'vace_blocks.4.ffn.2.weight', 'vace_blocks.4.cross_attn.norm_k.weight', 'vace_blocks.13.cross_attn.norm_k.weight', 'vace_blocks.13.modulation', 'vace_blocks.13.cross_attn.v.weight', 'vace_blocks.1.ffn.2.bias', 'vace_blocks.10.self_attn.o.weight', 'vace_blocks.6.self_attn.k.bias', 'vace_blocks.5.norm3.weight', 'vace_blocks.7.ffn.0.weight', 'vace_blocks.9.self_attn.o.weight', 'vace_blocks.2.cross_attn.o.weight', 'vace_blocks.4.self_attn.q.bias', 'vace_blocks.11.after_proj.weight', 'vace_blocks.8.after_proj.bias', 'vace_blocks.4.cross_attn.o.bias', 'vace_blocks.4.self_attn.q.weight', 'vace_blocks.0.ffn.0.weight', 'vace_blocks.0.ffn.2.bias', 'vace_blocks.4.cross_attn.v.weight', 'vace_blocks.14.ffn.2.weight', 'vace_blocks.6.self_attn.k.weight', 'vace_blocks.7.norm3.bias', 'vace_blocks.12.cross_attn.v.bias', 'vace_blocks.1.self_attn.v.weight', 'vace_blocks.5.self_attn.q.bias', 'vace_blocks.1.cross_attn.v.bias', 'vace_blocks.1.self_attn.o.bias', 'vace_blocks.0.modulation', 'vace_blocks.6.cross_attn.v.weight', 'vace_blocks.0.self_attn.q.weight', 'vace_blocks.11.self_attn.o.bias', 'vace_blocks.5.cross_attn.q.bias', 'vace_blocks.3.norm3.bias', 'vace_blocks.1.cross_attn.q.weight', 'vace_blocks.13.ffn.2.bias', 'vace_blocks.1.cross_attn.o.weight', 'vace_blocks.7.cross_attn.q.bias', 'vace_blocks.12.self_attn.o.weight', 'vace_blocks.2.ffn.0.bias', 'vace_blocks.3.after_proj.weight', 'vace_blocks.8.self_attn.o.weight', 'vace_blocks.10.self_attn.k.weight', 'vace_blocks.2.cross_attn.v.bias', 'vace_patch_embedding.weight', 'vace_blocks.4.self_attn.norm_k.weight', 'vace_blocks.3.self_attn.v.weight', 'vace_blocks.2.self_attn.v.bias', 'vace_blocks.0.self_attn.q.bias', 'vace_blocks.3.ffn.2.weight', 'vace_blocks.12.norm3.weight', 'vace_blocks.0.before_proj.bias', 'vace_blocks.10.cross_attn.norm_k.weight', 'vace_blocks.6.ffn.2.bias', 'vace_blocks.11.self_attn.norm_q.weight', 'vace_blocks.5.cross_attn.q.weight', 'vace_blocks.9.modulation', 'vace_blocks.13.self_attn.v.bias', 'vace_blocks.13.self_attn.q.weight', 'vace_blocks.8.cross_attn.norm_k.weight', 'vace_blocks.8.cross_attn.q.bias', 'vace_blocks.14.ffn.0.bias', 'vace_blocks.13.after_proj.bias', 'vace_blocks.1.cross_attn.norm_k.weight', 'vace_blocks.9.cross_attn.k.bias', 'vace_blocks.0.cross_attn.norm_q.weight', 'vace_blocks.8.self_attn.q.bias', 'vace_blocks.10.self_attn.k.bias', 'vace_blocks.7.after_proj.bias', 'vace_blocks.14.self_attn.norm_q.weight', 'vace_blocks.11.self_attn.k.weight', 'vace_blocks.0.cross_attn.v.weight', 'vace_blocks.8.ffn.0.bias', 'vace_blocks.13.self_attn.q.bias', 'vace_blocks.14.self_attn.o.bias', 'vace_blocks.8.cross_attn.o.bias', 'vace_blocks.3.cross_attn.o.bias', 'vace_blocks.11.norm3.bias', 'vace_blocks.10.self_attn.norm_k.weight', 'vace_blocks.0.cross_attn.o.bias', 'vace_blocks.0.before_proj.weight', 'vace_blocks.9.self_attn.norm_k.weight', 'vace_blocks.7.ffn.2.weight', 'vace_blocks.6.self_attn.norm_q.weight', 'vace_blocks.6.cross_attn.norm_q.weight', 'vace_blocks.2.cross_attn.q.weight', 'vace_blocks.5.ffn.2.weight', 'vace_blocks.11.cross_attn.v.weight', 'vace_blocks.10.self_attn.norm_q.weight', 'vace_blocks.8.self_attn.k.bias', 'vace_blocks.9.ffn.0.bias', 'vace_blocks.4.self_attn.o.weight', 'vace_blocks.14.ffn.0.weight', 'vace_blocks.7.self_attn.o.weight', 'vace_blocks.10.norm3.weight', 'vace_blocks.14.self_attn.k.bias', 'vace_blocks.13.self_attn.o.bias', 'vace_blocks.9.self_attn.norm_q.weight', 'vace_blocks.9.cross_attn.v.weight', 'vace_blocks.6.self_attn.v.weight', 'vace_blocks.9.self_attn.v.bias', 'vace_blocks.7.ffn.0.bias', 'vace_blocks.2.self_attn.norm_k.weight', 'vace_blocks.14.self_attn.k.weight', 'vace_blocks.6.norm3.weight', 'vace_blocks.14.self_attn.q.bias', 'vace_blocks.4.cross_attn.v.bias', 'vace_blocks.12.ffn.0.weight', 'vace_blocks.11.cross_attn.v.bias', 'vace_blocks.3.cross_attn.o.weight', 'vace_blocks.13.self_attn.v.weight', 'vace_blocks.12.self_attn.norm_q.weight', 'vace_blocks.3.cross_attn.k.bias', 'vace_blocks.5.ffn.2.bias', 'vace_blocks.13.cross_attn.o.weight', 'vace_blocks.14.self_attn.o.weight', 'vace_blocks.4.cross_attn.k.bias', 'vace_blocks.0.after_proj.bias', 'vace_blocks.0.cross_attn.q.bias', 'vace_blocks.14.cross_attn.q.bias', 'vace_blocks.5.after_proj.weight', 'vace_blocks.0.cross_attn.q.weight', 'vace_blocks.4.norm3.weight', 'vace_blocks.9.norm3.bias', 'vace_blocks.1.self_attn.q.bias', 'vace_blocks.10.cross_attn.k.bias', 'vace_blocks.9.cross_attn.norm_q.weight', 'vace_blocks.8.self_attn.v.bias', 'vace_blocks.8.norm3.bias', 'vace_blocks.4.self_attn.k.weight', 'vace_blocks.2.after_proj.bias', 'vace_blocks.2.cross_attn.v.weight', 'vace_blocks.9.self_attn.o.bias', 'vace_blocks.3.self_attn.k.weight', 'vace_blocks.6.self_attn.norm_k.weight', 'vace_blocks.11.cross_attn.o.weight', 'vace_blocks.2.ffn.0.weight', 'vace_blocks.4.ffn.0.weight', 'vace_blocks.5.ffn.0.weight', 'vace_blocks.10.cross_attn.k.weight', 'vace_blocks.1.self_attn.norm_k.weight', 'vace_blocks.2.after_proj.weight', 'vace_blocks.12.after_proj.bias', 'vace_blocks.10.self_attn.v.weight', 'vace_blocks.13.ffn.2.weight', 'vace_blocks.5.self_attn.o.weight', 'vace_blocks.14.cross_attn.o.weight', 'vace_blocks.3.modulation', 'vace_blocks.13.after_proj.weight', 'vace_blocks.4.after_proj.bias', 'vace_blocks.1.after_proj.bias', 'vace_blocks.4.cross_attn.q.weight', 'vace_blocks.14.cross_attn.q.weight', 'vace_blocks.8.cross_attn.k.bias', 'vace_blocks.11.cross_attn.k.bias', 'vace_blocks.12.cross_attn.o.weight', 'vace_blocks.1.cross_attn.q.bias', 'vace_blocks.13.cross_attn.q.weight', 'vace_blocks.14.cross_attn.k.weight', 'vace_blocks.13.self_attn.k.bias', 'vace_blocks.14.self_attn.v.bias', 'vace_blocks.0.cross_attn.norm_k.weight', 'vace_blocks.10.cross_attn.v.weight', 'vace_blocks.13.self_attn.norm_q.weight', 'vace_blocks.3.self_attn.norm_q.weight', 'vace_blocks.4.modulation', 'vace_blocks.7.cross_attn.norm_k.weight', 'vace_blocks.3.self_attn.o.weight', 'vace_blocks.4.ffn.2.bias', 'vace_blocks.2.norm3.weight', 'vace_blocks.11.cross_attn.norm_k.weight', 'vace_blocks.0.cross_attn.k.weight', 'vace_blocks.10.cross_attn.q.weight', 'vace_blocks.11.ffn.0.bias', 'vace_blocks.1.norm3.weight', 'vace_blocks.9.self_attn.k.weight', 'vace_blocks.14.after_proj.bias', 'vace_blocks.2.self_attn.k.weight', 'vace_blocks.13.self_attn.norm_k.weight', 'vace_blocks.7.self_attn.v.bias', 'vace_blocks.12.ffn.2.weight', 'vace_blocks.3.cross_attn.norm_q.weight', 'vace_blocks.6.cross_attn.o.bias', 'vace_blocks.4.cross_attn.k.weight', 'vace_blocks.13.cross_attn.k.bias', 'vace_blocks.12.after_proj.weight', 'vace_blocks.10.cross_attn.norm_q.weight', 'vace_blocks.14.cross_attn.v.weight', 'vace_blocks.4.norm3.bias', 'vace_blocks.7.after_proj.weight', 'vace_blocks.11.self_attn.v.weight', 'vace_blocks.2.self_attn.q.bias', 'vace_blocks.9.cross_attn.o.bias', 'vace_blocks.11.modulation', 'vace_blocks.10.self_attn.o.bias', 'vace_blocks.13.norm3.bias', 'vace_blocks.7.norm3.weight', 'vace_blocks.6.cross_attn.k.weight', 'vace_blocks.10.ffn.0.weight', 'vace_blocks.6.cross_attn.o.weight', 'vace_blocks.12.self_attn.o.bias', 'vace_blocks.7.self_attn.norm_k.weight', 'vace_blocks.9.after_proj.weight', 'vace_blocks.0.self_attn.v.bias', 'vace_blocks.7.cross_attn.o.weight', 'vace_blocks.3.ffn.2.bias', 'vace_blocks.5.self_attn.q.weight', 'vace_blocks.1.cross_attn.norm_q.weight', 'vace_blocks.3.ffn.0.weight', 'vace_blocks.9.self_attn.k.bias', 'vace_blocks.12.cross_attn.o.bias', 'vace_blocks.13.cross_attn.norm_q.weight', 'vace_blocks.10.ffn.2.bias', 'vace_blocks.3.cross_attn.v.weight', 'vace_blocks.11.after_proj.bias', 'vace_blocks.8.modulation', 'vace_blocks.1.self_attn.k.weight', 'vace_blocks.9.ffn.2.bias', 'vace_blocks.5.cross_attn.v.weight', 'vace_blocks.2.cross_attn.norm_k.weight', 'vace_blocks.8.self_attn.o.bias', 'vace_blocks.3.cross_attn.q.weight', 'vace_blocks.8.cross_attn.q.weight', 'vace_blocks.11.cross_attn.q.bias', 'vace_blocks.10.ffn.2.weight', 'vace_blocks.11.self_attn.v.bias', 'vace_blocks.12.ffn.2.bias', 'vace_blocks.4.self_attn.o.bias', 'vace_blocks.1.norm3.bias', 'vace_blocks.11.self_attn.q.bias', 'vace_blocks.7.ffn.2.bias', 'vace_blocks.14.cross_attn.v.bias', 'vace_blocks.12.modulation', 'vace_blocks.5.ffn.0.bias', 'vace_blocks.14.norm3.weight', 'vace_blocks.7.self_attn.k.bias', 'vace_blocks.5.self_attn.norm_k.weight', 'vace_blocks.13.ffn.0.weight', 'vace_blocks.12.self_attn.q.weight', 'vace_blocks.14.ffn.2.bias', 'vace_blocks.0.self_attn.norm_k.weight', 'vace_blocks.6.ffn.0.bias', 'vace_blocks.10.ffn.0.bias', 'vace_blocks.3.cross_attn.q.bias', 'vace_blocks.9.self_attn.v.weight', 'vace_blocks.12.self_attn.k.bias', 'vace_blocks.5.self_attn.k.weight', 'vace_blocks.8.cross_attn.o.weight', 'vace_blocks.7.cross_attn.o.bias', 'vace_blocks.6.cross_attn.q.weight', 'vace_blocks.2.self_attn.v.weight', 'vace_blocks.5.cross_attn.k.weight', 'vace_blocks.1.after_proj.weight', 'vace_blocks.2.cross_attn.o.bias', 'vace_blocks.6.self_attn.q.bias', 'vace_blocks.5.self_attn.v.weight', 'vace_blocks.5.cross_attn.o.weight', 'vace_blocks.6.modulation', 'vace_blocks.0.cross_attn.v.bias', 'vace_blocks.14.self_attn.q.weight', 'vace_blocks.5.modulation', 'vace_blocks.6.self_attn.o.bias', 'vace_blocks.8.self_attn.q.weight', 'vace_blocks.7.cross_attn.k.bias', 'vace_blocks.8.after_proj.weight', 'vace_blocks.13.cross_attn.o.bias', 'vace_blocks.1.ffn.0.bias', 'vace_blocks.14.modulation', 'vace_blocks.14.cross_attn.k.bias', 'vace_blocks.2.ffn.2.weight', 'vace_blocks.9.self_attn.q.weight', 'vace_blocks.9.after_proj.bias', 'vace_blocks.10.self_attn.q.bias', 'vace_blocks.1.self_attn.k.bias', 'vace_blocks.10.self_attn.v.bias', 'vace_blocks.3.self_attn.k.bias', 'vace_blocks.4.ffn.0.bias', 'vace_blocks.7.cross_attn.v.weight', 'vace_blocks.12.norm3.bias', 'vace_blocks.9.cross_attn.q.weight', 'vace_blocks.10.cross_attn.v.bias', 'vace_blocks.5.self_attn.norm_q.weight', 'vace_blocks.8.norm3.weight', 'vace_blocks.2.cross_attn.norm_q.weight', 'vace_blocks.0.norm3.bias', 'vace_blocks.14.cross_attn.o.bias', 'vace_blocks.12.self_attn.norm_k.weight', 'vace_blocks.4.after_proj.weight', 'vace_blocks.2.modulation', 'vace_blocks.7.self_attn.q.bias', 'vace_blocks.6.ffn.0.weight', 'vace_blocks.11.ffn.2.weight', 'vace_blocks.8.ffn.2.bias', 'vace_blocks.10.self_attn.q.weight', 'vace_blocks.11.self_attn.norm_k.weight', 'vace_blocks.7.cross_attn.q.weight', 'vace_blocks.0.cross_attn.o.weight', 'vace_blocks.5.after_proj.bias', 'vace_blocks.1.ffn.2.weight', 'vace_blocks.2.cross_attn.k.weight', 'vace_blocks.6.after_proj.bias', 'vace_blocks.11.self_attn.q.weight', 'vace_blocks.7.cross_attn.norm_q.weight', 'vace_blocks.12.self_attn.v.bias', 'vace_blocks.12.cross_attn.v.weight', 'vace_blocks.3.self_attn.q.weight', 'vace_blocks.14.cross_attn.norm_k.weight', 'vace_blocks.3.self_attn.o.bias', 'vace_blocks.7.self_attn.o.bias', 'vace_blocks.9.cross_attn.norm_k.weight', 'vace_blocks.5.cross_attn.o.bias', 'vace_blocks.0.self_attn.o.weight', 'vace_blocks.3.self_attn.v.bias', 'vace_blocks.0.self_attn.o.bias', 'vace_blocks.13.self_attn.k.weight', 'vace_blocks.12.self_attn.v.weight', 'vace_blocks.3.ffn.0.bias', 'vace_blocks.0.cross_attn.k.bias', 'vace_blocks.6.after_proj.weight', 'vace_blocks.0.ffn.0.bias', 'vace_blocks.6.cross_attn.k.bias', 'vace_blocks.5.self_attn.v.bias', 'vace_blocks.3.cross_attn.norm_k.weight', 'vace_blocks.0.norm3.weight', 'vace_blocks.8.self_attn.k.weight', 'vace_blocks.7.self_attn.norm_q.weight', 'vace_patch_embedding.bias', 'vace_blocks.6.ffn.2.weight', 'vace_blocks.7.modulation', 'vace_blocks.2.cross_attn.q.bias', 'vace_blocks.2.self_attn.o.weight', 'vace_blocks.8.ffn.2.weight', 'vace_blocks.9.ffn.2.weight', 'vace_blocks.4.cross_attn.q.bias', 'vace_blocks.11.norm3.weight', 'vace_blocks.6.cross_attn.q.bias', 'vace_blocks.11.cross_attn.o.bias', 'vace_blocks.9.norm3.weight', 'vace_blocks.4.self_attn.v.bias', 'vace_blocks.9.ffn.0.weight', 'vace_blocks.2.cross_attn.k.bias', 'vace_blocks.6.self_attn.q.weight', 'vace_blocks.3.cross_attn.v.bias', 'vace_blocks.13.ffn.0.bias', 'vace_blocks.13.self_attn.o.weight', 'vace_blocks.2.self_attn.norm_q.weight', 'vace_blocks.9.cross_attn.v.bias', 'vace_blocks.12.self_attn.q.bias', 'vace_blocks.1.modulation', 'vace_blocks.7.cross_attn.v.bias', 'vace_blocks.3.self_attn.norm_k.weight', 'vace_blocks.1.self_attn.v.bias', 'vace_blocks.0.self_attn.v.weight', 'vace_blocks.0.after_proj.weight', 'vace_blocks.7.self_attn.q.weight', 'vace_blocks.14.self_attn.norm_k.weight', 'vace_blocks.10.cross_attn.o.bias', 'vace_blocks.12.ffn.0.bias', 'vace_blocks.6.cross_attn.v.bias', 'vace_blocks.10.after_proj.bias', 'vace_blocks.0.self_attn.k.bias', 'vace_blocks.6.self_attn.o.weight', 'vace_blocks.8.self_attn.norm_q.weight', 'vace_blocks.9.cross_attn.k.weight', 'vace_blocks.5.cross_attn.k.bias', 'vace_blocks.8.cross_attn.v.bias', 'vace_blocks.10.after_proj.weight', 'vace_blocks.0.self_attn.k.weight', 'vace_blocks.7.self_attn.v.weight', 'vace_blocks.11.cross_attn.k.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.vace_blocks.0.modulation', 'model.vace_blocks.0.self_attn.q.weight', 'model.vace_blocks.0.self_attn.q.bias', 'model.vace_blocks.0.self_attn.k.weight', 'model.vace_blocks.0.self_attn.k.bias', 'model.vace_blocks.0.self_attn.v.weight', 'model.vace_blocks.0.self_attn.v.bias', 'model.vace_blocks.0.self_attn.o.weight', 'model.vace_blocks.0.self_attn.o.bias', 'model.vace_blocks.0.self_attn.norm_q.weight', 'model.vace_blocks.0.self_attn.norm_k.weight', 'model.vace_blocks.0.norm3.weight', 'model.vace_blocks.0.norm3.bias', 'model.vace_blocks.0.cross_attn.q.weight', 'model.vace_blocks.0.cross_attn.q.bias', 'model.vace_blocks.0.cross_attn.k.weight', 'model.vace_blocks.0.cross_attn.k.bias', 'model.vace_blocks.0.cross_attn.v.weight', 'model.vace_blocks.0.cross_attn.v.bias', 'model.vace_blocks.0.cross_attn.o.weight', 'model.vace_blocks.0.cross_attn.o.bias', 'model.vace_blocks.0.cross_attn.norm_q.weight', 'model.vace_blocks.0.cross_attn.norm_k.weight', 'model.vace_blocks.0.ffn.0.weight', 'model.vace_blocks.0.ffn.0.bias', 'model.vace_blocks.0.ffn.2.weight', 'model.vace_blocks.0.ffn.2.bias', 'model.vace_blocks.0.before_proj.weight', 'model.vace_blocks.0.before_proj.bias', 'model.vace_blocks.0.after_proj.weight', 'model.vace_blocks.0.after_proj.bias', 'model.vace_blocks.1.modulation', 'model.vace_blocks.1.self_attn.q.weight', 'model.vace_blocks.1.self_attn.q.bias', 'model.vace_blocks.1.self_attn.k.weight', 'model.vace_blocks.1.self_attn.k.bias', 'model.vace_blocks.1.self_attn.v.weight', 'model.vace_blocks.1.self_attn.v.bias', 'model.vace_blocks.1.self_attn.o.weight', 'model.vace_blocks.1.self_attn.o.bias', 'model.vace_blocks.1.self_attn.norm_q.weight', 'model.vace_blocks.1.self_attn.norm_k.weight', 'model.vace_blocks.1.norm3.weight', 'model.vace_blocks.1.norm3.bias', 'model.vace_blocks.1.cross_attn.q.weight', 'model.vace_blocks.1.cross_attn.q.bias', 'model.vace_blocks.1.cross_attn.k.weight', 'model.vace_blocks.1.cross_attn.k.bias', 'model.vace_blocks.1.cross_attn.v.weight', 'model.vace_blocks.1.cross_attn.v.bias', 'model.vace_blocks.1.cross_attn.o.weight', 'model.vace_blocks.1.cross_attn.o.bias', 'model.vace_blocks.1.cross_attn.norm_q.weight', 'model.vace_blocks.1.cross_attn.norm_k.weight', 'model.vace_blocks.1.ffn.0.weight', 'model.vace_blocks.1.ffn.0.bias', 'model.vace_blocks.1.ffn.2.weight', 'model.vace_blocks.1.ffn.2.bias', 'model.vace_blocks.1.after_proj.weight', 'model.vace_blocks.1.after_proj.bias', 'model.vace_blocks.2.modulation', 'model.vace_blocks.2.self_attn.q.weight', 'model.vace_blocks.2.self_attn.q.bias', 'model.vace_blocks.2.self_attn.k.weight', 'model.vace_blocks.2.self_attn.k.bias', 'model.vace_blocks.2.self_attn.v.weight', 'model.vace_blocks.2.self_attn.v.bias', 'model.vace_blocks.2.self_attn.o.weight', 'model.vace_blocks.2.self_attn.o.bias', 'model.vace_blocks.2.self_attn.norm_q.weight', 'model.vace_blocks.2.self_attn.norm_k.weight', 'model.vace_blocks.2.norm3.weight', 'model.vace_blocks.2.norm3.bias', 'model.vace_blocks.2.cross_attn.q.weight', 'model.vace_blocks.2.cross_attn.q.bias', 'model.vace_blocks.2.cross_attn.k.weight', 'model.vace_blocks.2.cross_attn.k.bias', 'model.vace_blocks.2.cross_attn.v.weight', 'model.vace_blocks.2.cross_attn.v.bias', 'model.vace_blocks.2.cross_attn.o.weight', 'model.vace_blocks.2.cross_attn.o.bias', 'model.vace_blocks.2.cross_attn.norm_q.weight', 'model.vace_blocks.2.cross_attn.norm_k.weight', 'model.vace_blocks.2.ffn.0.weight', 'model.vace_blocks.2.ffn.0.bias', 'model.vace_blocks.2.ffn.2.weight', 'model.vace_blocks.2.ffn.2.bias', 'model.vace_blocks.2.after_proj.weight', 'model.vace_blocks.2.after_proj.bias', 'model.vace_blocks.3.modulation', 'model.vace_blocks.3.self_attn.q.weight', 'model.vace_blocks.3.self_attn.q.bias', 'model.vace_blocks.3.self_attn.k.weight', 'model.vace_blocks.3.self_attn.k.bias', 'model.vace_blocks.3.self_attn.v.weight', 'model.vace_blocks.3.self_attn.v.bias', 'model.vace_blocks.3.self_attn.o.weight', 'model.vace_blocks.3.self_attn.o.bias', 'model.vace_blocks.3.self_attn.norm_q.weight', 'model.vace_blocks.3.self_attn.norm_k.weight', 'model.vace_blocks.3.norm3.weight', 'model.vace_blocks.3.norm3.bias', 'model.vace_blocks.3.cross_attn.q.weight', 'model.vace_blocks.3.cross_attn.q.bias', 'model.vace_blocks.3.cross_attn.k.weight', 'model.vace_blocks.3.cross_attn.k.bias', 'model.vace_blocks.3.cross_attn.v.weight', 'model.vace_blocks.3.cross_attn.v.bias', 'model.vace_blocks.3.cross_attn.o.weight', 'model.vace_blocks.3.cross_attn.o.bias', 'model.vace_blocks.3.cross_attn.norm_q.weight', 'model.vace_blocks.3.cross_attn.norm_k.weight', 'model.vace_blocks.3.ffn.0.weight', 'model.vace_blocks.3.ffn.0.bias', 'model.vace_blocks.3.ffn.2.weight', 'model.vace_blocks.3.ffn.2.bias', 'model.vace_blocks.3.after_proj.weight', 'model.vace_blocks.3.after_proj.bias', 'model.vace_blocks.4.modulation', 'model.vace_blocks.4.self_attn.q.weight', 'model.vace_blocks.4.self_attn.q.bias', 'model.vace_blocks.4.self_attn.k.weight', 'model.vace_blocks.4.self_attn.k.bias', 'model.vace_blocks.4.self_attn.v.weight', 'model.vace_blocks.4.self_attn.v.bias', 'model.vace_blocks.4.self_attn.o.weight', 'model.vace_blocks.4.self_attn.o.bias', 'model.vace_blocks.4.self_attn.norm_q.weight', 'model.vace_blocks.4.self_attn.norm_k.weight', 'model.vace_blocks.4.norm3.weight', 'model.vace_blocks.4.norm3.bias', 'model.vace_blocks.4.cross_attn.q.weight', 'model.vace_blocks.4.cross_attn.q.bias', 'model.vace_blocks.4.cross_attn.k.weight', 'model.vace_blocks.4.cross_attn.k.bias', 'model.vace_blocks.4.cross_attn.v.weight', 'model.vace_blocks.4.cross_attn.v.bias', 'model.vace_blocks.4.cross_attn.o.weight', 'model.vace_blocks.4.cross_attn.o.bias', 'model.vace_blocks.4.cross_attn.norm_q.weight', 'model.vace_blocks.4.cross_attn.norm_k.weight', 'model.vace_blocks.4.ffn.0.weight', 'model.vace_blocks.4.ffn.0.bias', 'model.vace_blocks.4.ffn.2.weight', 'model.vace_blocks.4.ffn.2.bias', 'model.vace_blocks.4.after_proj.weight', 'model.vace_blocks.4.after_proj.bias', 'model.vace_blocks.5.modulation', 'model.vace_blocks.5.self_attn.q.weight', 'model.vace_blocks.5.self_attn.q.bias', 'model.vace_blocks.5.self_attn.k.weight', 'model.vace_blocks.5.self_attn.k.bias', 'model.vace_blocks.5.self_attn.v.weight', 'model.vace_blocks.5.self_attn.v.bias', 'model.vace_blocks.5.self_attn.o.weight', 'model.vace_blocks.5.self_attn.o.bias', 'model.vace_blocks.5.self_attn.norm_q.weight', 'model.vace_blocks.5.self_attn.norm_k.weight', 'model.vace_blocks.5.norm3.weight', 'model.vace_blocks.5.norm3.bias', 'model.vace_blocks.5.cross_attn.q.weight', 'model.vace_blocks.5.cross_attn.q.bias', 'model.vace_blocks.5.cross_attn.k.weight', 'model.vace_blocks.5.cross_attn.k.bias', 'model.vace_blocks.5.cross_attn.v.weight', 'model.vace_blocks.5.cross_attn.v.bias', 'model.vace_blocks.5.cross_attn.o.weight', 'model.vace_blocks.5.cross_attn.o.bias', 'model.vace_blocks.5.cross_attn.norm_q.weight', 'model.vace_blocks.5.cross_attn.norm_k.weight', 'model.vace_blocks.5.ffn.0.weight', 'model.vace_blocks.5.ffn.0.bias', 'model.vace_blocks.5.ffn.2.weight', 'model.vace_blocks.5.ffn.2.bias', 'model.vace_blocks.5.after_proj.weight', 'model.vace_blocks.5.after_proj.bias', 'model.vace_blocks.6.modulation', 'model.vace_blocks.6.self_attn.q.weight', 'model.vace_blocks.6.self_attn.q.bias', 'model.vace_blocks.6.self_attn.k.weight', 'model.vace_blocks.6.self_attn.k.bias', 'model.vace_blocks.6.self_attn.v.weight', 'model.vace_blocks.6.self_attn.v.bias', 'model.vace_blocks.6.self_attn.o.weight', 'model.vace_blocks.6.self_attn.o.bias', 'model.vace_blocks.6.self_attn.norm_q.weight', 'model.vace_blocks.6.self_attn.norm_k.weight', 'model.vace_blocks.6.norm3.weight', 'model.vace_blocks.6.norm3.bias', 'model.vace_blocks.6.cross_attn.q.weight', 'model.vace_blocks.6.cross_attn.q.bias', 'model.vace_blocks.6.cross_attn.k.weight', 'model.vace_blocks.6.cross_attn.k.bias', 'model.vace_blocks.6.cross_attn.v.weight', 'model.vace_blocks.6.cross_attn.v.bias', 'model.vace_blocks.6.cross_attn.o.weight', 'model.vace_blocks.6.cross_attn.o.bias', 'model.vace_blocks.6.cross_attn.norm_q.weight', 'model.vace_blocks.6.cross_attn.norm_k.weight', 'model.vace_blocks.6.ffn.0.weight', 'model.vace_blocks.6.ffn.0.bias', 'model.vace_blocks.6.ffn.2.weight', 'model.vace_blocks.6.ffn.2.bias', 'model.vace_blocks.6.after_proj.weight', 'model.vace_blocks.6.after_proj.bias', 'model.vace_blocks.7.modulation', 'model.vace_blocks.7.self_attn.q.weight', 'model.vace_blocks.7.self_attn.q.bias', 'model.vace_blocks.7.self_attn.k.weight', 'model.vace_blocks.7.self_attn.k.bias', 'model.vace_blocks.7.self_attn.v.weight', 'model.vace_blocks.7.self_attn.v.bias', 'model.vace_blocks.7.self_attn.o.weight', 'model.vace_blocks.7.self_attn.o.bias', 'model.vace_blocks.7.self_attn.norm_q.weight', 'model.vace_blocks.7.self_attn.norm_k.weight', 'model.vace_blocks.7.norm3.weight', 'model.vace_blocks.7.norm3.bias', 'model.vace_blocks.7.cross_attn.q.weight', 'model.vace_blocks.7.cross_attn.q.bias', 'model.vace_blocks.7.cross_attn.k.weight', 'model.vace_blocks.7.cross_attn.k.bias', 'model.vace_blocks.7.cross_attn.v.weight', 'model.vace_blocks.7.cross_attn.v.bias', 'model.vace_blocks.7.cross_attn.o.weight', 'model.vace_blocks.7.cross_attn.o.bias', 'model.vace_blocks.7.cross_attn.norm_q.weight', 'model.vace_blocks.7.cross_attn.norm_k.weight', 'model.vace_blocks.7.ffn.0.weight', 'model.vace_blocks.7.ffn.0.bias', 'model.vace_blocks.7.ffn.2.weight', 'model.vace_blocks.7.ffn.2.bias', 'model.vace_blocks.7.after_proj.weight', 'model.vace_blocks.7.after_proj.bias', 'model.vace_blocks.8.modulation', 'model.vace_blocks.8.self_attn.q.weight', 'model.vace_blocks.8.self_attn.q.bias', 'model.vace_blocks.8.self_attn.k.weight', 'model.vace_blocks.8.self_attn.k.bias', 'model.vace_blocks.8.self_attn.v.weight', 'model.vace_blocks.8.self_attn.v.bias', 'model.vace_blocks.8.self_attn.o.weight', 'model.vace_blocks.8.self_attn.o.bias', 'model.vace_blocks.8.self_attn.norm_q.weight', 'model.vace_blocks.8.self_attn.norm_k.weight', 'model.vace_blocks.8.norm3.weight', 'model.vace_blocks.8.norm3.bias', 'model.vace_blocks.8.cross_attn.q.weight', 'model.vace_blocks.8.cross_attn.q.bias', 'model.vace_blocks.8.cross_attn.k.weight', 'model.vace_blocks.8.cross_attn.k.bias', 'model.vace_blocks.8.cross_attn.v.weight', 'model.vace_blocks.8.cross_attn.v.bias', 'model.vace_blocks.8.cross_attn.o.weight', 'model.vace_blocks.8.cross_attn.o.bias', 'model.vace_blocks.8.cross_attn.norm_q.weight', 'model.vace_blocks.8.cross_attn.norm_k.weight', 'model.vace_blocks.8.ffn.0.weight', 'model.vace_blocks.8.ffn.0.bias', 'model.vace_blocks.8.ffn.2.weight', 'model.vace_blocks.8.ffn.2.bias', 'model.vace_blocks.8.after_proj.weight', 'model.vace_blocks.8.after_proj.bias', 'model.vace_blocks.9.modulation', 'model.vace_blocks.9.self_attn.q.weight', 'model.vace_blocks.9.self_attn.q.bias', 'model.vace_blocks.9.self_attn.k.weight', 'model.vace_blocks.9.self_attn.k.bias', 'model.vace_blocks.9.self_attn.v.weight', 'model.vace_blocks.9.self_attn.v.bias', 'model.vace_blocks.9.self_attn.o.weight', 'model.vace_blocks.9.self_attn.o.bias', 'model.vace_blocks.9.self_attn.norm_q.weight', 'model.vace_blocks.9.self_attn.norm_k.weight', 'model.vace_blocks.9.norm3.weight', 'model.vace_blocks.9.norm3.bias', 'model.vace_blocks.9.cross_attn.q.weight', 'model.vace_blocks.9.cross_attn.q.bias', 'model.vace_blocks.9.cross_attn.k.weight', 'model.vace_blocks.9.cross_attn.k.bias', 'model.vace_blocks.9.cross_attn.v.weight', 'model.vace_blocks.9.cross_attn.v.bias', 'model.vace_blocks.9.cross_attn.o.weight', 'model.vace_blocks.9.cross_attn.o.bias', 'model.vace_blocks.9.cross_attn.norm_q.weight', 'model.vace_blocks.9.cross_attn.norm_k.weight', 'model.vace_blocks.9.ffn.0.weight', 'model.vace_blocks.9.ffn.0.bias', 'model.vace_blocks.9.ffn.2.weight', 'model.vace_blocks.9.ffn.2.bias', 'model.vace_blocks.9.after_proj.weight', 'model.vace_blocks.9.after_proj.bias', 'model.vace_blocks.10.modulation', 'model.vace_blocks.10.self_attn.q.weight', 'model.vace_blocks.10.self_attn.q.bias', 'model.vace_blocks.10.self_attn.k.weight', 'model.vace_blocks.10.self_attn.k.bias', 'model.vace_blocks.10.self_attn.v.weight', 'model.vace_blocks.10.self_attn.v.bias', 'model.vace_blocks.10.self_attn.o.weight', 'model.vace_blocks.10.self_attn.o.bias', 'model.vace_blocks.10.self_attn.norm_q.weight', 'model.vace_blocks.10.self_attn.norm_k.weight', 'model.vace_blocks.10.norm3.weight', 'model.vace_blocks.10.norm3.bias', 'model.vace_blocks.10.cross_attn.q.weight', 'model.vace_blocks.10.cross_attn.q.bias', 'model.vace_blocks.10.cross_attn.k.weight', 'model.vace_blocks.10.cross_attn.k.bias', 'model.vace_blocks.10.cross_attn.v.weight', 'model.vace_blocks.10.cross_attn.v.bias', 'model.vace_blocks.10.cross_attn.o.weight', 'model.vace_blocks.10.cross_attn.o.bias', 'model.vace_blocks.10.cross_attn.norm_q.weight', 'model.vace_blocks.10.cross_attn.norm_k.weight', 'model.vace_blocks.10.ffn.0.weight', 'model.vace_blocks.10.ffn.0.bias', 'model.vace_blocks.10.ffn.2.weight', 'model.vace_blocks.10.ffn.2.bias', 'model.vace_blocks.10.after_proj.weight', 'model.vace_blocks.10.after_proj.bias', 'model.vace_blocks.11.modulation', 'model.vace_blocks.11.self_attn.q.weight', 'model.vace_blocks.11.self_attn.q.bias', 'model.vace_blocks.11.self_attn.k.weight', 'model.vace_blocks.11.self_attn.k.bias', 'model.vace_blocks.11.self_attn.v.weight', 'model.vace_blocks.11.self_attn.v.bias', 'model.vace_blocks.11.self_attn.o.weight', 'model.vace_blocks.11.self_attn.o.bias', 'model.vace_blocks.11.self_attn.norm_q.weight', 'model.vace_blocks.11.self_attn.norm_k.weight', 'model.vace_blocks.11.norm3.weight', 'model.vace_blocks.11.norm3.bias', 'model.vace_blocks.11.cross_attn.q.weight', 'model.vace_blocks.11.cross_attn.q.bias', 'model.vace_blocks.11.cross_attn.k.weight', 'model.vace_blocks.11.cross_attn.k.bias', 'model.vace_blocks.11.cross_attn.v.weight', 'model.vace_blocks.11.cross_attn.v.bias', 'model.vace_blocks.11.cross_attn.o.weight', 'model.vace_blocks.11.cross_attn.o.bias', 'model.vace_blocks.11.cross_attn.norm_q.weight', 'model.vace_blocks.11.cross_attn.norm_k.weight', 'model.vace_blocks.11.ffn.0.weight', 'model.vace_blocks.11.ffn.0.bias', 'model.vace_blocks.11.ffn.2.weight', 'model.vace_blocks.11.ffn.2.bias', 'model.vace_blocks.11.after_proj.weight', 'model.vace_blocks.11.after_proj.bias', 'model.vace_blocks.12.modulation', 'model.vace_blocks.12.self_attn.q.weight', 'model.vace_blocks.12.self_attn.q.bias', 'model.vace_blocks.12.self_attn.k.weight', 'model.vace_blocks.12.self_attn.k.bias', 'model.vace_blocks.12.self_attn.v.weight', 'model.vace_blocks.12.self_attn.v.bias', 'model.vace_blocks.12.self_attn.o.weight', 'model.vace_blocks.12.self_attn.o.bias', 'model.vace_blocks.12.self_attn.norm_q.weight', 'model.vace_blocks.12.self_attn.norm_k.weight', 'model.vace_blocks.12.norm3.weight', 'model.vace_blocks.12.norm3.bias', 'model.vace_blocks.12.cross_attn.q.weight', 'model.vace_blocks.12.cross_attn.q.bias', 'model.vace_blocks.12.cross_attn.k.weight', 'model.vace_blocks.12.cross_attn.k.bias', 'model.vace_blocks.12.cross_attn.v.weight', 'model.vace_blocks.12.cross_attn.v.bias', 'model.vace_blocks.12.cross_attn.o.weight', 'model.vace_blocks.12.cross_attn.o.bias', 'model.vace_blocks.12.cross_attn.norm_q.weight', 'model.vace_blocks.12.cross_attn.norm_k.weight', 'model.vace_blocks.12.ffn.0.weight', 'model.vace_blocks.12.ffn.0.bias', 'model.vace_blocks.12.ffn.2.weight', 'model.vace_blocks.12.ffn.2.bias', 'model.vace_blocks.12.after_proj.weight', 'model.vace_blocks.12.after_proj.bias', 'model.vace_blocks.13.modulation', 'model.vace_blocks.13.self_attn.q.weight', 'model.vace_blocks.13.self_attn.q.bias', 'model.vace_blocks.13.self_attn.k.weight', 'model.vace_blocks.13.self_attn.k.bias', 'model.vace_blocks.13.self_attn.v.weight', 'model.vace_blocks.13.self_attn.v.bias', 'model.vace_blocks.13.self_attn.o.weight', 'model.vace_blocks.13.self_attn.o.bias', 'model.vace_blocks.13.self_attn.norm_q.weight', 'model.vace_blocks.13.self_attn.norm_k.weight', 'model.vace_blocks.13.norm3.weight', 'model.vace_blocks.13.norm3.bias', 'model.vace_blocks.13.cross_attn.q.weight', 'model.vace_blocks.13.cross_attn.q.bias', 'model.vace_blocks.13.cross_attn.k.weight', 'model.vace_blocks.13.cross_attn.k.bias', 'model.vace_blocks.13.cross_attn.v.weight', 'model.vace_blocks.13.cross_attn.v.bias', 'model.vace_blocks.13.cross_attn.o.weight', 'model.vace_blocks.13.cross_attn.o.bias', 'model.vace_blocks.13.cross_attn.norm_q.weight', 'model.vace_blocks.13.cross_attn.norm_k.weight', 'model.vace_blocks.13.ffn.0.weight', 'model.vace_blocks.13.ffn.0.bias', 'model.vace_blocks.13.ffn.2.weight', 'model.vace_blocks.13.ffn.2.bias', 'model.vace_blocks.13.after_proj.weight', 'model.vace_blocks.13.after_proj.bias', 'model.vace_blocks.14.modulation', 'model.vace_blocks.14.self_attn.q.weight', 'model.vace_blocks.14.self_attn.q.bias', 'model.vace_blocks.14.self_attn.k.weight', 'model.vace_blocks.14.self_attn.k.bias', 'model.vace_blocks.14.self_attn.v.weight', 'model.vace_blocks.14.self_attn.v.bias', 'model.vace_blocks.14.self_attn.o.weight', 'model.vace_blocks.14.self_attn.o.bias', 'model.vace_blocks.14.self_attn.norm_q.weight', 'model.vace_blocks.14.self_attn.norm_k.weight', 'model.vace_blocks.14.norm3.weight', 'model.vace_blocks.14.norm3.bias', 'model.vace_blocks.14.cross_attn.q.weight', 'model.vace_blocks.14.cross_attn.q.bias', 'model.vace_blocks.14.cross_attn.k.weight', 'model.vace_blocks.14.cross_attn.k.bias', 'model.vace_blocks.14.cross_attn.v.weight', 'model.vace_blocks.14.cross_attn.v.bias', 'model.vace_blocks.14.cross_attn.o.weight', 'model.vace_blocks.14.cross_attn.o.bias', 'model.vace_blocks.14.cross_attn.norm_q.weight', 'model.vace_blocks.14.cross_attn.norm_k.weight', 'model.vace_blocks.14.ffn.0.weight', 'model.vace_blocks.14.ffn.0.bias', 'model.vace_blocks.14.ffn.2.weight', 'model.vace_blocks.14.ffn.2.bias', 'model.vace_blocks.14.after_proj.weight', 'model.vace_blocks.14.after_proj.bias', 'model.vace_patch_embedding.weight', 'model.vace_patch_embedding.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare generator\n",
    "import causvid.models.wan.wan_wrapper\n",
    "importlib.reload(causvid.models.wan.wan_wrapper)\n",
    "importlib.reload(causvid.models.wan.vace_causal_model)\n",
    "from causvid.models.wan.wan_wrapper import VaceCausalWanDiffusionWrapper\n",
    "\n",
    "generator = VaceCausalWanDiffusionWrapper() # this loads the base \"wan_models/Wan2.1-T2V-1.3B/\" model\n",
    "generator.load_state_dict(causvid_state_dict, strict=False)#True)\n",
    "generator.model.vace_blocks = vace.vace_blocks\n",
    "generator.model.vace_patch_embedding = vace.vace_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4971096-6160-436d-8ef2-43160aef2685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): VaceWanAttentionBlock(\n",
      "    (norm1): WanLayerNorm((1536,), eps=1e-06, elementwise_affine=False)\n",
      "    (self_attn): WanSelfAttention(\n",
      "      (q): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (k): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (v): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (o): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (norm_q): WanRMSNorm()\n",
      "      (norm_k): WanRMSNorm()\n",
      "    )\n",
      "    (norm3): WanLayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "    (cross_attn): WanT2VCrossAttention(\n",
      "      (q): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (k): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (v): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (o): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (norm_q): WanRMSNorm()\n",
      "      (norm_k): WanRMSNorm()\n",
      "    )\n",
      "    (norm2): WanLayerNorm((1536,), eps=1e-06, elementwise_affine=False)\n",
      "    (ffn): Sequential(\n",
      "      (0): Linear(in_features=1536, out_features=8960, bias=True)\n",
      "      (1): GELU(approximate='tanh')\n",
      "      (2): Linear(in_features=8960, out_features=1536, bias=True)\n",
      "    )\n",
      "    (before_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (after_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "  )\n",
      "  (1-14): 14 x VaceWanAttentionBlock(\n",
      "    (norm1): WanLayerNorm((1536,), eps=1e-06, elementwise_affine=False)\n",
      "    (self_attn): WanSelfAttention(\n",
      "      (q): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (k): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (v): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (o): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (norm_q): WanRMSNorm()\n",
      "      (norm_k): WanRMSNorm()\n",
      "    )\n",
      "    (norm3): WanLayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
      "    (cross_attn): WanT2VCrossAttention(\n",
      "      (q): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (k): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (v): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (o): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "      (norm_q): WanRMSNorm()\n",
      "      (norm_k): WanRMSNorm()\n",
      "    )\n",
      "    (norm2): WanLayerNorm((1536,), eps=1e-06, elementwise_affine=False)\n",
      "    (ffn): Sequential(\n",
      "      (0): Linear(in_features=1536, out_features=8960, bias=True)\n",
      "      (1): GELU(approximate='tanh')\n",
      "      (2): Linear(in_features=8960, out_features=1536, bias=True)\n",
      "    )\n",
      "    (after_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(generator.model.vace_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "131d781c-cd50-4911-9915-3fcae546a66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(causvid\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mwan\u001b[38;5;241m.\u001b[39mmy_inference)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcausvid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwan\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmy_inference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MyInferencePipeline\n\u001b[0;32m----> 5\u001b[0m my_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mMyInferencePipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtext_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mvae\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvae\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CausVid/causvid/models/wan/my_inference.py:14\u001b[0m, in \u001b[0;36mMyInferencePipeline.__init__\u001b[0;34m(self, generator, text_encoder, vae, args, dtype, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Step 1: Initialize all models\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_encoder \u001b[38;5;241m=\u001b[39m text_encoder\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:1369\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1367\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 928 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:928\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 928\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:955\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 955\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:1362\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1362\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1363\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1364\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen moving module from meta to a different device.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1365\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device."
     ]
    }
   ],
   "source": [
    "import causvid.models.wan.my_inference\n",
    "importlib.reload(causvid.models.wan.my_inference)\n",
    "from causvid.models.wan.my_inference import MyInferencePipeline\n",
    "\n",
    "my_pipeline = MyInferencePipeline(generator=generator,\n",
    "                                  text_encoder=text_encoder,\n",
    "                                  vae=vae,\n",
    "                                  args=config, dtype=torch.bfloat16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d089c-6ec6-45e7-a820-4a12ea2e3e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ca27973-61d2-4a83-8a28-8f061f9cf215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bbb1b49f03408bb1dba79ad72f1e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'VaceCausalWanModel' object has no attribute '_forward_vace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt_index \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(prompt_dataset))):\n\u001b[1;32m      6\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m [prompt_dataset[prompt_index]]\n\u001b[0;32m----> 8\u001b[0m     video \u001b[38;5;241m=\u001b[39m \u001b[43mmy_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampled_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_prompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompts\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     13\u001b[0m     export_to_video(\n\u001b[1;32m     14\u001b[0m         video, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_output_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_index\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m), fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m~/CausVid/causvid/models/wan/my_inference.py:155\u001b[0m, in \u001b[0;36mMyInferencePipeline.inference\u001b[0;34m(self, noise, text_prompts, start_latents, return_latents)\u001b[0m\n\u001b[1;32m    151\u001b[0m timestep \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\n\u001b[1;32m    152\u001b[0m     [batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_frame_per_block], device\u001b[38;5;241m=\u001b[39mnoise\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64) \u001b[38;5;241m*\u001b[39m current_timestep\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdenoising_step_list) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 155\u001b[0m     denoised_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoisy_image_or_video\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoisy_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconditional_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconditional_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvace_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvace_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvace_context_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvace_context_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrossattn_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrossattn_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_frame_per_block\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43mblock_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_frame_per_block\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_seq_length\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     next_timestep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdenoising_step_list[index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    167\u001b[0m     noisy_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39madd_noise(\n\u001b[1;32m    168\u001b[0m         denoised_pred\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    169\u001b[0m         torch\u001b[38;5;241m.\u001b[39mrandn_like(denoised_pred\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m                    dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m    173\u001b[0m     )\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m0\u001b[39m, denoised_pred\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/CausVid/causvid/models/wan/wan_wrapper.py:246\u001b[0m, in \u001b[0;36mVaceCausalWanDiffusionWrapper.forward\u001b[0;34m(self, noisy_image_or_video, conditional_dict, timestep, vace_context, vace_context_scale, kv_cache, crossattn_cache, current_start, current_end)\u001b[0m\n\u001b[1;32m    243\u001b[0m     input_timestep \u001b[38;5;241m=\u001b[39m timestep\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kv_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 246\u001b[0m     flow_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoisy_image_or_video\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_timestep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvace_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvace_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvace_context_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvace_context_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcrossattn_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrossattn_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_end\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     flow_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m    258\u001b[0m         noisy_image_or_video\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m    259\u001b[0m         t\u001b[38;5;241m=\u001b[39minput_timestep, context\u001b[38;5;241m=\u001b[39mprompt_embeds,\n\u001b[1;32m    260\u001b[0m         vace_context\u001b[38;5;241m=\u001b[39mvace_context, vace_context_scale\u001b[38;5;241m=\u001b[39mvace_context_scale,\n\u001b[1;32m    261\u001b[0m         seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len\n\u001b[1;32m    262\u001b[0m     )\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/CausVid/causvid/models/wan/causal_model.py:698\u001b[0m, in \u001b[0;36mCausalWanModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    696\u001b[0m ):\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkv_cache\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 698\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_train(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/CausVid/causvid/models/wan/vace_causal_model.py:219\u001b[0m, in \u001b[0;36mVaceCausalWanModel._forward_inference\u001b[0;34m(self, x, t, context, vace_context, vace_context_scale, seq_len, clip_fea, y, kv_cache, crossattn_cache, current_start, current_end)\u001b[0m\n\u001b[1;32m    208\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    209\u001b[0m     e\u001b[38;5;241m=\u001b[39me0,\n\u001b[1;32m    210\u001b[0m     seq_lens\u001b[38;5;241m=\u001b[39mseq_lens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     block_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_mask\n\u001b[1;32m    216\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# DO VACE HERE\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m hints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_vace\u001b[49m(x, vace_context, seq_len, kwargs)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# DO VACE HERE\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_custom_forward\u001b[39m(module):\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:273\u001b[0m, in \u001b[0;36mModelMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_dict[name]\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# call PyTorch's https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/causvid/lib/python3.10/site-packages/torch/nn/modules/module.py:1962\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1962\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1964\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VaceCausalWanModel' object has no attribute '_forward_vace'"
     ]
    }
   ],
   "source": [
    "sampled_noise = torch.randn(\n",
    "    [1, 21, 16, 60, 104], device=device, dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "for prompt_index in tqdm(range(len(prompt_dataset))):\n",
    "    prompts = [prompt_dataset[prompt_index]]\n",
    "\n",
    "    video = my_pipeline.inference(\n",
    "        noise=sampled_noise,\n",
    "        text_prompts=prompts\n",
    "    )[0].permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "    export_to_video(\n",
    "        video, os.path.join(output_folder, f\"my_output_{prompt_index:03d}.mp4\"), fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66c934-b001-43da-95da-3822059aca8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
