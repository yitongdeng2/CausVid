{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1349a2ed-4eb4-4097-8b5d-f825b1899814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.set_grad_enabled(mode=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.utils import export_to_video\n",
    "from causvid.data import TextDataset\n",
    "from omegaconf import OmegaConf\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "62875dec-f69d-4612-9bfb-27d706278967",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"first_test\"\n",
    "logs_dir = os.path.join(\"logs\", exp_name)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "config_path = \"configs/wan_causal_dmd.yaml\"\n",
    "config = OmegaConf.load(config_path)\n",
    "checkpoint_folder = os.path.join(\"checkpoints\", \"autoregressive_checkpoint\")\n",
    "output_folder = logs_dir \n",
    "prompt_file_path = os.path.join(\"prompt_files\", \"prompt2.txt\")\n",
    "prompt_dataset = TextDataset(prompt_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "28d4412f-2005-4514-a562-d139f1606f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two rugged nordic warriors in detailed medieval armor, bare-knuckle boxing inside a wooden fighting ring, surrounded by torchlight and roaring spectators, cinematic composition, cold misty air, sparks and sweat flying, dramatic side lighting, ultra-detailed leather and steel textures, tense atmosphere, epic fantasy realism, cinematic photography, shallow depth of field, volumetric fog, inspired by Game of Thrones, high-contrast chiaroscuro lighting, moody blue-gray tones, filmic realism, masterpiece digital art by Karla Ortiz and Ruan Jia, 8k resolution', 'a massive polar bear and a giant grizzly bear locked in brutal combat inside a wooden fighting ring, snow swirling around them, blood and fur flying, cinematic low-angle shot, cold blue lighting, frosty breath, shards of ice, roaring spectators in furs, ancient nordic arena carved from ice and wood, epic fantasy realism, moody atmosphere, volumetric fog, dramatic side lighting, masterpiece digital art by Karla Ortiz and Ruan Jia, inspired by Game of Thrones, ultra-detailed fur and muscles, 8k cinematic film still', 'a chinese kung fu master and a european gladiator facing off inside an ancient stone fighting ring, cinematic east-meets-west duel, flowing robes versus heavy armor, intense expressions, dynamic martial arts motion, sparks flying from weapons, torchlight and drifting smoke, warm orange light contrasting cold shadows, highly detailed armor and silk textures, historical fantasy realism, inspired by Game of Thrones and Hero, atmospheric depth, motion blur, dramatic composition, masterpiece 8k cinematic shot', 'two battle-worn robots of contrasting designs boxing in a metallic arena, one sleek and futuristic, the other rugged and industrial, sparks and oil splashing, cinematic lighting, moody smoke and haze, dark steel tones, reflections of firelight on metal surfaces, dramatic camera angle, detailed mechanical textures, realistic motion blur, dystopian atmosphere, cinematic realism, inspired by Game of Thrones cinematography and Blade Runner tone, masterpiece digital art, 8k ultra detail']\n"
     ]
    }
   ],
   "source": [
    "print(prompt_dataset.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a146f0ea-b03b-4371-9156-94d198c41119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare generator\n",
    "from causvid.models.wan.wan_wrapper import CausalWanDiffusionWrapper\n",
    "generator = CausalWanDiffusionWrapper() # this loads the base \"wan_models/Wan2.1-T2V-1.3B/\" model\n",
    "causvid_state_dict = torch.load(os.path.join(checkpoint_folder, \"model.pt\"), map_location=device)['generator'] # this loads causvid model\n",
    "generator.load_state_dict(causvid_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f6bc478-9321-418c-98e7-bc2f7298053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare text encoder\n",
    "from causvid.models.wan.wan_wrapper import WanTextEncoder\n",
    "text_encoder = WanTextEncoder() # default text encoder, in CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5a63db-f0fe-4077-85c3-a20f20bb4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare vae\n",
    "from causvid.models.wan.wan_wrapper import WanVAEWrapper\n",
    "vae = WanVAEWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a38f1cf3-fa1c-47ea-b066-7d458fce54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in dim?  96\n",
      "patch size? (1, 2, 2)\n",
      "patch size?  (1, 2, 2)\n",
      "OrderedDict([('weight', tensor(..., device='meta', size=(1536, 96, 1, 2, 2))), ('bias', tensor(..., device='meta', size=(1536,)))])\n"
     ]
    }
   ],
   "source": [
    "# VACE\n",
    "import VACE_essentials.vace_wan_model\n",
    "importlib.reload(VACE_essentials.vace_wan_model)\n",
    "from VACE_essentials.vace_wan_model import VaceWanModel\n",
    "vace_ckpt = os.path.join(\"VACE_essentials\", \"vace_wan_models\", \"Wan2.1-VACE-1.3B\")\n",
    "vace = VaceWanModel.from_pretrained(vace_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21ac333d-5da2-4a89-b604-c4222c6097c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KV inference with 3 frames per block\n"
     ]
    }
   ],
   "source": [
    "import causvid.models.wan.my_inference\n",
    "importlib.reload(causvid.models.wan.my_inference)\n",
    "from causvid.models.wan.my_inference import MyInferencePipeline\n",
    "\n",
    "my_pipeline = MyInferencePipeline(generator=generator,\n",
    "                                  text_encoder=text_encoder,\n",
    "                                  vae=vae,\n",
    "                                  args=config, dtype=torch.bfloat16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a943a891-3589-4f03-819f-c8eab095a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c1f4f4887c444d9f2b694b0650028f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled_noise = torch.randn(\n",
    "    [1, 21, 16, 60, 104], device=device, dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "for prompt_index in tqdm(range(len(prompt_dataset))):\n",
    "    prompts = [prompt_dataset[prompt_index]]\n",
    "\n",
    "    video = my_pipeline.inference(\n",
    "        noise=sampled_noise,\n",
    "        text_prompts=prompts\n",
    "    )[0].permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "    export_to_video(\n",
    "        video, os.path.join(output_folder, f\"my_output_{prompt_index:03d}.mp4\"), fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "53d5ac30-401d-4b71-8fff-1ba95bee6c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VaceCausalWanModel were not initialized from the model checkpoint at wan_models/Wan2.1-T2V-1.3B/ and are newly initialized: ['vace_blocks.4.cross_attn.norm_q.weight', 'vace_blocks.8.cross_attn.k.weight', 'vace_blocks.8.self_attn.norm_k.weight', 'vace_blocks.4.cross_attn.o.weight', 'vace_blocks.1.cross_attn.v.weight', 'vace_blocks.9.cross_attn.o.weight', 'vace_blocks.0.self_attn.norm_q.weight', 'vace_blocks.12.cross_attn.k.bias', 'vace_blocks.1.self_attn.o.weight', 'vace_blocks.10.modulation', 'vace_blocks.10.cross_attn.q.bias', 'vace_blocks.5.self_attn.k.bias', 'vace_blocks.5.cross_attn.norm_q.weight', 'vace_blocks.12.cross_attn.norm_k.weight', 'vace_blocks.7.cross_attn.k.weight', 'vace_blocks.13.cross_attn.q.bias', 'vace_blocks.11.self_attn.k.bias', 'vace_blocks.11.cross_attn.norm_q.weight', 'vace_blocks.11.ffn.0.weight', 'vace_blocks.14.self_attn.v.weight', 'vace_blocks.13.cross_attn.v.bias', 'vace_blocks.8.cross_attn.v.weight', 'vace_blocks.7.self_attn.k.weight', 'vace_blocks.13.norm3.weight', 'vace_blocks.8.self_attn.v.weight', 'vace_blocks.10.cross_attn.o.weight', 'vace_blocks.8.cross_attn.norm_q.weight', 'vace_blocks.3.self_attn.q.bias', 'vace_blocks.3.norm3.weight', 'vace_blocks.5.cross_attn.v.bias', 'vace_blocks.1.self_attn.norm_q.weight', 'vace_blocks.1.cross_attn.k.weight', 'vace_blocks.6.norm3.bias', 'vace_blocks.13.cross_attn.k.weight', 'vace_blocks.1.cross_attn.o.bias', 'vace_blocks.6.self_attn.v.bias', 'vace_blocks.1.cross_attn.k.bias', 'vace_blocks.6.cross_attn.norm_k.weight', 'vace_blocks.2.self_attn.q.weight', 'vace_blocks.2.self_attn.k.bias', 'vace_blocks.12.self_attn.k.weight', 'vace_blocks.12.cross_attn.norm_q.weight', 'vace_blocks.5.self_attn.o.bias', 'vace_blocks.2.ffn.2.bias', 'vace_blocks.11.self_attn.o.weight', 'vace_blocks.0.ffn.2.weight', 'vace_blocks.12.cross_attn.q.weight', 'vace_blocks.12.cross_attn.k.weight', 'vace_blocks.1.ffn.0.weight', 'vace_blocks.10.norm3.bias', 'vace_blocks.4.self_attn.k.bias', 'vace_blocks.9.self_attn.q.bias', 'vace_blocks.14.cross_attn.norm_q.weight', 'vace_blocks.5.norm3.bias', 'vace_blocks.2.norm3.bias', 'vace_blocks.14.norm3.bias', 'vace_blocks.11.cross_attn.q.weight', 'vace_blocks.12.cross_attn.q.bias', 'vace_blocks.1.self_attn.q.weight', 'vace_blocks.14.after_proj.weight', 'vace_blocks.2.self_attn.o.bias', 'vace_blocks.9.cross_attn.q.bias', 'vace_blocks.3.after_proj.bias', 'vace_blocks.8.ffn.0.weight', 'vace_blocks.4.self_attn.norm_q.weight', 'vace_blocks.4.self_attn.v.weight', 'vace_blocks.3.cross_attn.k.weight', 'vace_blocks.11.ffn.2.bias', 'vace_blocks.5.cross_attn.norm_k.weight', 'vace_blocks.4.ffn.2.weight', 'vace_blocks.4.cross_attn.norm_k.weight', 'vace_blocks.13.cross_attn.norm_k.weight', 'vace_blocks.13.modulation', 'vace_blocks.13.cross_attn.v.weight', 'vace_blocks.1.ffn.2.bias', 'vace_blocks.10.self_attn.o.weight', 'vace_blocks.6.self_attn.k.bias', 'vace_blocks.5.norm3.weight', 'vace_blocks.7.ffn.0.weight', 'vace_blocks.9.self_attn.o.weight', 'vace_blocks.2.cross_attn.o.weight', 'vace_blocks.4.self_attn.q.bias', 'vace_blocks.11.after_proj.weight', 'vace_blocks.8.after_proj.bias', 'vace_blocks.4.cross_attn.o.bias', 'vace_blocks.4.self_attn.q.weight', 'vace_blocks.0.ffn.0.weight', 'vace_blocks.0.ffn.2.bias', 'vace_blocks.4.cross_attn.v.weight', 'vace_blocks.14.ffn.2.weight', 'vace_blocks.6.self_attn.k.weight', 'vace_blocks.7.norm3.bias', 'vace_blocks.12.cross_attn.v.bias', 'vace_blocks.1.self_attn.v.weight', 'vace_blocks.5.self_attn.q.bias', 'vace_blocks.1.cross_attn.v.bias', 'vace_blocks.1.self_attn.o.bias', 'vace_blocks.0.modulation', 'vace_blocks.6.cross_attn.v.weight', 'vace_blocks.0.self_attn.q.weight', 'vace_blocks.11.self_attn.o.bias', 'vace_blocks.5.cross_attn.q.bias', 'vace_blocks.3.norm3.bias', 'vace_blocks.1.cross_attn.q.weight', 'vace_blocks.13.ffn.2.bias', 'vace_blocks.1.cross_attn.o.weight', 'vace_blocks.7.cross_attn.q.bias', 'vace_blocks.12.self_attn.o.weight', 'vace_blocks.2.ffn.0.bias', 'vace_blocks.3.after_proj.weight', 'vace_blocks.8.self_attn.o.weight', 'vace_blocks.10.self_attn.k.weight', 'vace_blocks.2.cross_attn.v.bias', 'vace_patch_embedding.weight', 'vace_blocks.4.self_attn.norm_k.weight', 'vace_blocks.3.self_attn.v.weight', 'vace_blocks.2.self_attn.v.bias', 'vace_blocks.0.self_attn.q.bias', 'vace_blocks.3.ffn.2.weight', 'vace_blocks.12.norm3.weight', 'vace_blocks.0.before_proj.bias', 'vace_blocks.10.cross_attn.norm_k.weight', 'vace_blocks.6.ffn.2.bias', 'vace_blocks.11.self_attn.norm_q.weight', 'vace_blocks.5.cross_attn.q.weight', 'vace_blocks.9.modulation', 'vace_blocks.13.self_attn.v.bias', 'vace_blocks.13.self_attn.q.weight', 'vace_blocks.8.cross_attn.norm_k.weight', 'vace_blocks.8.cross_attn.q.bias', 'vace_blocks.14.ffn.0.bias', 'vace_blocks.13.after_proj.bias', 'vace_blocks.1.cross_attn.norm_k.weight', 'vace_blocks.9.cross_attn.k.bias', 'vace_blocks.0.cross_attn.norm_q.weight', 'vace_blocks.8.self_attn.q.bias', 'vace_blocks.10.self_attn.k.bias', 'vace_blocks.7.after_proj.bias', 'vace_blocks.14.self_attn.norm_q.weight', 'vace_blocks.11.self_attn.k.weight', 'vace_blocks.0.cross_attn.v.weight', 'vace_blocks.8.ffn.0.bias', 'vace_blocks.13.self_attn.q.bias', 'vace_blocks.14.self_attn.o.bias', 'vace_blocks.8.cross_attn.o.bias', 'vace_blocks.3.cross_attn.o.bias', 'vace_blocks.11.norm3.bias', 'vace_blocks.10.self_attn.norm_k.weight', 'vace_blocks.0.cross_attn.o.bias', 'vace_blocks.0.before_proj.weight', 'vace_blocks.9.self_attn.norm_k.weight', 'vace_blocks.7.ffn.2.weight', 'vace_blocks.6.self_attn.norm_q.weight', 'vace_blocks.6.cross_attn.norm_q.weight', 'vace_blocks.2.cross_attn.q.weight', 'vace_blocks.5.ffn.2.weight', 'vace_blocks.11.cross_attn.v.weight', 'vace_blocks.10.self_attn.norm_q.weight', 'vace_blocks.8.self_attn.k.bias', 'vace_blocks.9.ffn.0.bias', 'vace_blocks.4.self_attn.o.weight', 'vace_blocks.14.ffn.0.weight', 'vace_blocks.7.self_attn.o.weight', 'vace_blocks.10.norm3.weight', 'vace_blocks.14.self_attn.k.bias', 'vace_blocks.13.self_attn.o.bias', 'vace_blocks.9.self_attn.norm_q.weight', 'vace_blocks.9.cross_attn.v.weight', 'vace_blocks.6.self_attn.v.weight', 'vace_blocks.9.self_attn.v.bias', 'vace_blocks.7.ffn.0.bias', 'vace_blocks.2.self_attn.norm_k.weight', 'vace_blocks.14.self_attn.k.weight', 'vace_blocks.6.norm3.weight', 'vace_blocks.14.self_attn.q.bias', 'vace_blocks.4.cross_attn.v.bias', 'vace_blocks.12.ffn.0.weight', 'vace_blocks.11.cross_attn.v.bias', 'vace_blocks.3.cross_attn.o.weight', 'vace_blocks.13.self_attn.v.weight', 'vace_blocks.12.self_attn.norm_q.weight', 'vace_blocks.3.cross_attn.k.bias', 'vace_blocks.5.ffn.2.bias', 'vace_blocks.13.cross_attn.o.weight', 'vace_blocks.14.self_attn.o.weight', 'vace_blocks.4.cross_attn.k.bias', 'vace_blocks.0.after_proj.bias', 'vace_blocks.0.cross_attn.q.bias', 'vace_blocks.14.cross_attn.q.bias', 'vace_blocks.5.after_proj.weight', 'vace_blocks.0.cross_attn.q.weight', 'vace_blocks.4.norm3.weight', 'vace_blocks.9.norm3.bias', 'vace_blocks.1.self_attn.q.bias', 'vace_blocks.10.cross_attn.k.bias', 'vace_blocks.9.cross_attn.norm_q.weight', 'vace_blocks.8.self_attn.v.bias', 'vace_blocks.8.norm3.bias', 'vace_blocks.4.self_attn.k.weight', 'vace_blocks.2.after_proj.bias', 'vace_blocks.2.cross_attn.v.weight', 'vace_blocks.9.self_attn.o.bias', 'vace_blocks.3.self_attn.k.weight', 'vace_blocks.6.self_attn.norm_k.weight', 'vace_blocks.11.cross_attn.o.weight', 'vace_blocks.2.ffn.0.weight', 'vace_blocks.4.ffn.0.weight', 'vace_blocks.5.ffn.0.weight', 'vace_blocks.10.cross_attn.k.weight', 'vace_blocks.1.self_attn.norm_k.weight', 'vace_blocks.2.after_proj.weight', 'vace_blocks.12.after_proj.bias', 'vace_blocks.10.self_attn.v.weight', 'vace_blocks.13.ffn.2.weight', 'vace_blocks.5.self_attn.o.weight', 'vace_blocks.14.cross_attn.o.weight', 'vace_blocks.3.modulation', 'vace_blocks.13.after_proj.weight', 'vace_blocks.4.after_proj.bias', 'vace_blocks.1.after_proj.bias', 'vace_blocks.4.cross_attn.q.weight', 'vace_blocks.14.cross_attn.q.weight', 'vace_blocks.8.cross_attn.k.bias', 'vace_blocks.11.cross_attn.k.bias', 'vace_blocks.12.cross_attn.o.weight', 'vace_blocks.1.cross_attn.q.bias', 'vace_blocks.13.cross_attn.q.weight', 'vace_blocks.14.cross_attn.k.weight', 'vace_blocks.13.self_attn.k.bias', 'vace_blocks.14.self_attn.v.bias', 'vace_blocks.0.cross_attn.norm_k.weight', 'vace_blocks.10.cross_attn.v.weight', 'vace_blocks.13.self_attn.norm_q.weight', 'vace_blocks.3.self_attn.norm_q.weight', 'vace_blocks.4.modulation', 'vace_blocks.7.cross_attn.norm_k.weight', 'vace_blocks.3.self_attn.o.weight', 'vace_blocks.4.ffn.2.bias', 'vace_blocks.2.norm3.weight', 'vace_blocks.11.cross_attn.norm_k.weight', 'vace_blocks.0.cross_attn.k.weight', 'vace_blocks.10.cross_attn.q.weight', 'vace_blocks.11.ffn.0.bias', 'vace_blocks.1.norm3.weight', 'vace_blocks.9.self_attn.k.weight', 'vace_blocks.14.after_proj.bias', 'vace_blocks.2.self_attn.k.weight', 'vace_blocks.13.self_attn.norm_k.weight', 'vace_blocks.7.self_attn.v.bias', 'vace_blocks.12.ffn.2.weight', 'vace_blocks.3.cross_attn.norm_q.weight', 'vace_blocks.6.cross_attn.o.bias', 'vace_blocks.4.cross_attn.k.weight', 'vace_blocks.13.cross_attn.k.bias', 'vace_blocks.12.after_proj.weight', 'vace_blocks.10.cross_attn.norm_q.weight', 'vace_blocks.14.cross_attn.v.weight', 'vace_blocks.4.norm3.bias', 'vace_blocks.7.after_proj.weight', 'vace_blocks.11.self_attn.v.weight', 'vace_blocks.2.self_attn.q.bias', 'vace_blocks.9.cross_attn.o.bias', 'vace_blocks.11.modulation', 'vace_blocks.10.self_attn.o.bias', 'vace_blocks.13.norm3.bias', 'vace_blocks.7.norm3.weight', 'vace_blocks.6.cross_attn.k.weight', 'vace_blocks.10.ffn.0.weight', 'vace_blocks.6.cross_attn.o.weight', 'vace_blocks.12.self_attn.o.bias', 'vace_blocks.7.self_attn.norm_k.weight', 'vace_blocks.9.after_proj.weight', 'vace_blocks.0.self_attn.v.bias', 'vace_blocks.7.cross_attn.o.weight', 'vace_blocks.3.ffn.2.bias', 'vace_blocks.5.self_attn.q.weight', 'vace_blocks.1.cross_attn.norm_q.weight', 'vace_blocks.3.ffn.0.weight', 'vace_blocks.9.self_attn.k.bias', 'vace_blocks.12.cross_attn.o.bias', 'vace_blocks.13.cross_attn.norm_q.weight', 'vace_blocks.10.ffn.2.bias', 'vace_blocks.3.cross_attn.v.weight', 'vace_blocks.11.after_proj.bias', 'vace_blocks.8.modulation', 'vace_blocks.1.self_attn.k.weight', 'vace_blocks.9.ffn.2.bias', 'vace_blocks.5.cross_attn.v.weight', 'vace_blocks.2.cross_attn.norm_k.weight', 'vace_blocks.8.self_attn.o.bias', 'vace_blocks.3.cross_attn.q.weight', 'vace_blocks.8.cross_attn.q.weight', 'vace_blocks.11.cross_attn.q.bias', 'vace_blocks.10.ffn.2.weight', 'vace_blocks.11.self_attn.v.bias', 'vace_blocks.12.ffn.2.bias', 'vace_blocks.4.self_attn.o.bias', 'vace_blocks.1.norm3.bias', 'vace_blocks.11.self_attn.q.bias', 'vace_blocks.7.ffn.2.bias', 'vace_blocks.14.cross_attn.v.bias', 'vace_blocks.12.modulation', 'vace_blocks.5.ffn.0.bias', 'vace_blocks.14.norm3.weight', 'vace_blocks.7.self_attn.k.bias', 'vace_blocks.5.self_attn.norm_k.weight', 'vace_blocks.13.ffn.0.weight', 'vace_blocks.12.self_attn.q.weight', 'vace_blocks.14.ffn.2.bias', 'vace_blocks.0.self_attn.norm_k.weight', 'vace_blocks.6.ffn.0.bias', 'vace_blocks.10.ffn.0.bias', 'vace_blocks.3.cross_attn.q.bias', 'vace_blocks.9.self_attn.v.weight', 'vace_blocks.12.self_attn.k.bias', 'vace_blocks.5.self_attn.k.weight', 'vace_blocks.8.cross_attn.o.weight', 'vace_blocks.7.cross_attn.o.bias', 'vace_blocks.6.cross_attn.q.weight', 'vace_blocks.2.self_attn.v.weight', 'vace_blocks.5.cross_attn.k.weight', 'vace_blocks.1.after_proj.weight', 'vace_blocks.2.cross_attn.o.bias', 'vace_blocks.6.self_attn.q.bias', 'vace_blocks.5.self_attn.v.weight', 'vace_blocks.5.cross_attn.o.weight', 'vace_blocks.6.modulation', 'vace_blocks.0.cross_attn.v.bias', 'vace_blocks.14.self_attn.q.weight', 'vace_blocks.5.modulation', 'vace_blocks.6.self_attn.o.bias', 'vace_blocks.8.self_attn.q.weight', 'vace_blocks.7.cross_attn.k.bias', 'vace_blocks.8.after_proj.weight', 'vace_blocks.13.cross_attn.o.bias', 'vace_blocks.1.ffn.0.bias', 'vace_blocks.14.modulation', 'vace_blocks.14.cross_attn.k.bias', 'vace_blocks.2.ffn.2.weight', 'vace_blocks.9.self_attn.q.weight', 'vace_blocks.9.after_proj.bias', 'vace_blocks.10.self_attn.q.bias', 'vace_blocks.1.self_attn.k.bias', 'vace_blocks.10.self_attn.v.bias', 'vace_blocks.3.self_attn.k.bias', 'vace_blocks.4.ffn.0.bias', 'vace_blocks.7.cross_attn.v.weight', 'vace_blocks.12.norm3.bias', 'vace_blocks.9.cross_attn.q.weight', 'vace_blocks.10.cross_attn.v.bias', 'vace_blocks.5.self_attn.norm_q.weight', 'vace_blocks.8.norm3.weight', 'vace_blocks.2.cross_attn.norm_q.weight', 'vace_blocks.0.norm3.bias', 'vace_blocks.14.cross_attn.o.bias', 'vace_blocks.12.self_attn.norm_k.weight', 'vace_blocks.4.after_proj.weight', 'vace_blocks.2.modulation', 'vace_blocks.7.self_attn.q.bias', 'vace_blocks.6.ffn.0.weight', 'vace_blocks.11.ffn.2.weight', 'vace_blocks.8.ffn.2.bias', 'vace_blocks.10.self_attn.q.weight', 'vace_blocks.11.self_attn.norm_k.weight', 'vace_blocks.7.cross_attn.q.weight', 'vace_blocks.0.cross_attn.o.weight', 'vace_blocks.5.after_proj.bias', 'vace_blocks.1.ffn.2.weight', 'vace_blocks.2.cross_attn.k.weight', 'vace_blocks.6.after_proj.bias', 'vace_blocks.11.self_attn.q.weight', 'vace_blocks.7.cross_attn.norm_q.weight', 'vace_blocks.12.self_attn.v.bias', 'vace_blocks.12.cross_attn.v.weight', 'vace_blocks.3.self_attn.q.weight', 'vace_blocks.14.cross_attn.norm_k.weight', 'vace_blocks.3.self_attn.o.bias', 'vace_blocks.7.self_attn.o.bias', 'vace_blocks.9.cross_attn.norm_k.weight', 'vace_blocks.5.cross_attn.o.bias', 'vace_blocks.0.self_attn.o.weight', 'vace_blocks.3.self_attn.v.bias', 'vace_blocks.0.self_attn.o.bias', 'vace_blocks.13.self_attn.k.weight', 'vace_blocks.12.self_attn.v.weight', 'vace_blocks.3.ffn.0.bias', 'vace_blocks.0.cross_attn.k.bias', 'vace_blocks.6.after_proj.weight', 'vace_blocks.0.ffn.0.bias', 'vace_blocks.6.cross_attn.k.bias', 'vace_blocks.5.self_attn.v.bias', 'vace_blocks.3.cross_attn.norm_k.weight', 'vace_blocks.0.norm3.weight', 'vace_blocks.8.self_attn.k.weight', 'vace_blocks.7.self_attn.norm_q.weight', 'vace_patch_embedding.bias', 'vace_blocks.6.ffn.2.weight', 'vace_blocks.7.modulation', 'vace_blocks.2.cross_attn.q.bias', 'vace_blocks.2.self_attn.o.weight', 'vace_blocks.8.ffn.2.weight', 'vace_blocks.9.ffn.2.weight', 'vace_blocks.4.cross_attn.q.bias', 'vace_blocks.11.norm3.weight', 'vace_blocks.6.cross_attn.q.bias', 'vace_blocks.11.cross_attn.o.bias', 'vace_blocks.9.norm3.weight', 'vace_blocks.4.self_attn.v.bias', 'vace_blocks.9.ffn.0.weight', 'vace_blocks.2.cross_attn.k.bias', 'vace_blocks.6.self_attn.q.weight', 'vace_blocks.3.cross_attn.v.bias', 'vace_blocks.13.ffn.0.bias', 'vace_blocks.13.self_attn.o.weight', 'vace_blocks.2.self_attn.norm_q.weight', 'vace_blocks.9.cross_attn.v.bias', 'vace_blocks.12.self_attn.q.bias', 'vace_blocks.1.modulation', 'vace_blocks.7.cross_attn.v.bias', 'vace_blocks.3.self_attn.norm_k.weight', 'vace_blocks.1.self_attn.v.bias', 'vace_blocks.0.self_attn.v.weight', 'vace_blocks.0.after_proj.weight', 'vace_blocks.7.self_attn.q.weight', 'vace_blocks.14.self_attn.norm_k.weight', 'vace_blocks.10.cross_attn.o.bias', 'vace_blocks.12.ffn.0.bias', 'vace_blocks.6.cross_attn.v.bias', 'vace_blocks.10.after_proj.bias', 'vace_blocks.0.self_attn.k.bias', 'vace_blocks.6.self_attn.o.weight', 'vace_blocks.8.self_attn.norm_q.weight', 'vace_blocks.9.cross_attn.k.weight', 'vace_blocks.5.cross_attn.k.bias', 'vace_blocks.8.cross_attn.v.bias', 'vace_blocks.10.after_proj.weight', 'vace_blocks.0.self_attn.k.weight', 'vace_blocks.7.self_attn.v.weight', 'vace_blocks.11.cross_attn.k.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in dim?  96\n",
      "patch size? (1, 2, 2)\n",
      "patch size?  (1, 2, 2)\n",
      "OrderedDict([('weight', tensor(..., device='meta', size=(1536, 96, 1, 2, 2))), ('bias', tensor(..., device='meta', size=(1536,)))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare generator\n",
    "import causvid.models.wan.wan_wrapper\n",
    "importlib.reload(causvid.models.wan.wan_wrapper)\n",
    "importlib.reload(causvid.models.wan.vace_causal_model)\n",
    "from causvid.models.wan.wan_wrapper import VaceCausalWanDiffusionWrapper\n",
    "\n",
    "generator = VaceCausalWanDiffusionWrapper() # this loads the base \"wan_models/Wan2.1-T2V-1.3B/\" model\n",
    "generator.load_state_dict(causvid_state_dict, strict=False)#True)\n",
    "# generator.model.vace_blocks = vace.vace_blocks\n",
    "# generator.model.vace_patch_embedding = vace.vace_patch_embedding\n",
    "\n",
    "# copy over key parts from original vace\n",
    "if next(generator.model.vace_blocks.parameters(), None) is not None and generator.model.vace_blocks.parameters().__iter__().__next__().is_meta:\n",
    "    generator.model.vace_blocks.to_empty(device=generator.model.device)\n",
    "generator.model.vace_blocks.load_state_dict(vace.vace_blocks.state_dict(), strict=True)\n",
    "\n",
    "if next(generator.model.vace_patch_embedding.parameters(), None) is not None and generator.model.vace_patch_embedding.parameters().__iter__().__next__().is_meta:\n",
    "    generator.model.vace_patch_embedding.to_empty(device=generator.model.device)\n",
    "generator.model.vace_patch_embedding.load_state_dict(vace.vace_patch_embedding.state_dict(), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "131d781c-cd50-4911-9915-3fcae546a66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KV inference with 3 frames per block\n"
     ]
    }
   ],
   "source": [
    "import causvid.models.wan.my_inference\n",
    "importlib.reload(causvid.models.wan.my_inference)\n",
    "from causvid.models.wan.my_inference import MyInferencePipeline\n",
    "\n",
    "my_pipeline = MyInferencePipeline(generator=generator,\n",
    "                                  text_encoder=text_encoder,\n",
    "                                  vae=vae,\n",
    "                                  args=config, dtype=torch.bfloat16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4ca27973-61d2-4a83-8a28-8f061f9cf215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ae47f7fadb42eabc0b40e5c2dc871a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_blocks?? 7\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "num_blocks?? 7\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "num_blocks?? 7\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "num_blocks?? 7\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  0\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  4680\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  4680\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  9360\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  9360\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  14040\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  14040\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  18720\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  18720\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  23400\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  23400\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  28080\n",
      "t:  tensor([[1000, 1000, 1000]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[757, 757, 757]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[522, 522, 522]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n",
      "t:  tensor([[0, 0, 0]], device='cuda:0')\n",
      "e.shape:  torch.Size([3, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "e0.shape:  torch.Size([1, 3, 6, 1536])\n",
      "seq_lens:  tensor([4680])\n",
      "current_start:  28080\n",
      "item in vace_context:  torch.Size([96, 21, 60, 104])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "u shape after vace patch embedding:  torch.Size([1, 1536, 21, 30, 52])\n",
      "u shape after reshaping:  torch.Size([1, 32760, 1536])\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj:  Linear(in_features=1536, out_features=1536, bias=True)\n",
      "c shape:  torch.Size([1, 4680, 1536])\n",
      "self.before_proj(c) shape:  torch.Size([1, 4680, 1536])\n",
      "x.shape:  torch.Size([1, 4680, 1536])\n",
      "current_end:  32760\n"
     ]
    }
   ],
   "source": [
    "sampled_noise = torch.randn(\n",
    "    [1, 21, 16, 60, 104], device=device, dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "for prompt_index in tqdm(range(len(prompt_dataset))):\n",
    "    prompts = [prompt_dataset[prompt_index]]\n",
    "\n",
    "    video = my_pipeline.inference(\n",
    "        noise=sampled_noise,\n",
    "        text_prompts=prompts\n",
    "    )[0].permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "    export_to_video(\n",
    "        video, os.path.join(output_folder, f\"vace_output_{prompt_index:03d}.mp4\"), fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66c934-b001-43da-95da-3822059aca8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94adf11a-a6ce-42f8-bea3-d74c2e974d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
