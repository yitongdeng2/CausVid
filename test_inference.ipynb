{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1349a2ed-4eb4-4097-8b5d-f825b1899814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.set_grad_enabled(mode=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers.utils import export_to_video\n",
    "from causvid.data import TextDataset\n",
    "from omegaconf import OmegaConf\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62875dec-f69d-4612-9bfb-27d706278967",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"first_test\"\n",
    "logs_dir = os.path.join(\"logs\", exp_name)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "config_path = \"configs/wan_causal_dmd.yaml\"\n",
    "config = OmegaConf.load(config_path)\n",
    "checkpoint_folder = os.path.join(\"checkpoints\", \"autoregressive_checkpoint\")\n",
    "output_folder = logs_dir \n",
    "prompt_file_path = os.path.join(\"prompt_files\", \"prompt1.txt\")\n",
    "prompt_dataset = TextDataset(prompt_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a146f0ea-b03b-4371-9156-94d198c41119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare generator\n",
    "from causvid.models.wan.wan_wrapper import CausalWanDiffusionWrapper\n",
    "generator = CausalWanDiffusionWrapper() # this loads the base \"wan_models/Wan2.1-T2V-1.3B/\" model\n",
    "causvid_state_dict = torch.load(os.path.join(checkpoint_folder, \"model.pt\"), map_location=device)['generator'] # this loads causvid model\n",
    "generator.load_state_dict(causvid_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f6bc478-9321-418c-98e7-bc2f7298053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare text encoder\n",
    "from causvid.models.wan.wan_wrapper import WanTextEncoder\n",
    "text_encoder = WanTextEncoder() # default text encoder, in CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5a63db-f0fe-4077-85c3-a20f20bb4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare vae\n",
    "from causvid.models.wan.wan_wrapper import WanVAEWrapper\n",
    "vae = WanVAEWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a38f1cf3-fa1c-47ea-b066-7d458fce54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VACE\n",
    "import VACE_essentials.vace_wan_model\n",
    "importlib.reload(VACE_essentials.vace_wan_model)\n",
    "from VACE_essentials.vace_wan_model import VaceWanModel\n",
    "vace_ckpt = os.path.join(\"VACE_essentials\", \"vace_wan_models\", \"Wan2.1-VACE-1.3B\")\n",
    "vace = VaceWanModel.from_pretrained(vace_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21ac333d-5da2-4a89-b604-c4222c6097c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KV inference with 3 frames per block\n"
     ]
    }
   ],
   "source": [
    "import causvid.models.wan.my_inference\n",
    "importlib.reload(causvid.models.wan.my_inference)\n",
    "from causvid.models.wan.my_inference import MyInferencePipeline\n",
    "\n",
    "my_pipeline = MyInferencePipeline(generator=generator,\n",
    "                                  text_encoder=text_encoder,\n",
    "                                  vae=vae,\n",
    "                                  vace=vace,\n",
    "                                  args=config, dtype=torch.bfloat16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a943a891-3589-4f03-819f-c8eab095a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c1f4f4887c444d9f2b694b0650028f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled_noise = torch.randn(\n",
    "    [1, 21, 16, 60, 104], device=device, dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "for prompt_index in tqdm(range(len(prompt_dataset))):\n",
    "    prompts = [prompt_dataset[prompt_index]]\n",
    "\n",
    "    video = my_pipeline.inference(\n",
    "        noise=sampled_noise,\n",
    "        text_prompts=prompts\n",
    "    )[0].permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "    export_to_video(\n",
    "        video, os.path.join(output_folder, f\"my_output_{prompt_index:03d}.mp4\"), fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53d5ac30-401d-4b71-8fff-1ba95bee6c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare generator\n",
    "import causvid.models.wan.wan_wrapper\n",
    "importlib.reload(causvid.models.wan.wan_wrapper)\n",
    "from causvid.models.wan.wan_wrapper import VaceCausalWanDiffusionWrapper\n",
    "\n",
    "generator = VaceCausalWanDiffusionWrapper() # this loads the base \"wan_models/Wan2.1-T2V-1.3B/\" model\n",
    "causvid_state_dict = torch.load(os.path.join(checkpoint_folder, \"model.pt\"), map_location=device)['generator'] # this loads causvid model\n",
    "generator.load_state_dict(causvid_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "131d781c-cd50-4911-9915-3fcae546a66e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MyInferencePipeline.__init__() got an unexpected keyword argument 'vace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(causvid\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mwan\u001b[38;5;241m.\u001b[39mmy_inference)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcausvid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwan\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmy_inference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MyInferencePipeline\n\u001b[0;32m----> 5\u001b[0m my_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mMyInferencePipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtext_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mvae\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvae\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mvace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: MyInferencePipeline.__init__() got an unexpected keyword argument 'vace'"
     ]
    }
   ],
   "source": [
    "import causvid.models.wan.my_inference\n",
    "importlib.reload(causvid.models.wan.my_inference)\n",
    "from causvid.models.wan.my_inference import MyInferencePipeline\n",
    "\n",
    "my_pipeline = MyInferencePipeline(generator=generator,\n",
    "                                  text_encoder=text_encoder,\n",
    "                                  vae=vae,\n",
    "                                  args=config, dtype=torch.bfloat16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca27973-61d2-4a83-8a28-8f061f9cf215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
