{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57429b6c-35a6-42b2-8c78-004869003e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causvid.models.wan.causal_inference import InferencePipeline\n",
    "from diffusers.utils import export_to_video\n",
    "from causvid.data import TextDataset\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "\n",
    "exp_name = \"first_test\"\n",
    "logs_dir = os.path.join(\"logs\", exp_name)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "class Args(argparse.Namespace):\n",
    "  config_path = \"configs/wan_causal_dmd.yaml\"\n",
    "  checkpoint_folder = os.path.join(\"checkpoints\", \"autoregressive_checkpoint\")\n",
    "  output_folder = logs_dir \n",
    "  prompt_file_path = os.path.join(\"prompt_files\", \"prompt1.txt\")\n",
    "args = Args()\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "config = OmegaConf.load(args.config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f70ca2-d771-4b40-b928-5d77064596cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KV inference with 3 frames per block\n"
     ]
    }
   ],
   "source": [
    "pipeline = InferencePipeline(config, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6dd3b4f-0750-4fd0-b1f1-0bbd46426fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.65s/it]\n"
     ]
    }
   ],
   "source": [
    "pipeline.to(device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "state_dict = torch.load(os.path.join(args.checkpoint_folder, \"model.pt\"), map_location=\"cpu\")[\n",
    "    'generator']\n",
    "\n",
    "pipeline.generator.load_state_dict(\n",
    "    state_dict, strict=True\n",
    ")\n",
    "\n",
    "dataset = TextDataset(args.prompt_file_path)\n",
    "\n",
    "sampled_noise = torch.randn(\n",
    "    [1, 21, 16, 60, 104], device=\"cuda\", dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "os.makedirs(args.output_folder, exist_ok=True)\n",
    "\n",
    "for prompt_index in tqdm(range(len(dataset))):\n",
    "    prompts = [dataset[prompt_index]]\n",
    "\n",
    "    video = pipeline.inference(\n",
    "        noise=sampled_noise,\n",
    "        text_prompts=prompts\n",
    "    )[0].permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "    export_to_video(\n",
    "        video, os.path.join(args.output_folder, f\"output_{prompt_index:03d}.mp4\"), fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832419a-ba44-41c5-9d77-44818fe49fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
