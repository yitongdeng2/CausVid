{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57429b6c-35a6-42b2-8c78-004869003e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causvid.models.wan.causal_inference import InferencePipeline\n",
    "from diffusers.utils import export_to_video\n",
    "from causvid.data import TextDataset\n",
    "from omegaconf import OmegaConf\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "\n",
    "exp_name = \"first_test\"\n",
    "logs_dir = os.path.join(\"logs\", exp_name)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "class Args(argparse.Namespace):\n",
    "  config_path = \"configs/wan_causal_dmd.yaml\"\n",
    "  checkpoint_folder = os.path.join(\"checkpoints\", \"autoregressive_checkpoint\")\n",
    "  output_folder = logs_dir \n",
    "  prompt_file_path = os.path.join(\"prompt_files\", \"prompt1.txt\")\n",
    "args = Args()\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "config = OmegaConf.load(args.config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f70ca2-d771-4b40-b928-5d77064596cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KV inference with 3 frames per block\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = InferencePipeline(config, device=\"cuda\")\n",
    "pipeline.to(device=\"cuda\", dtype=torch.bfloat16)\n",
    "state_dict = torch.load(os.path.join(args.checkpoint_folder, \"model.pt\"), map_location=\"cpu\")[\n",
    "    'generator']\n",
    "pipeline.generator.load_state_dict(\n",
    "    state_dict, strict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea707b5f-c95e-4a84-b3fc-dd388158e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(args.prompt_file_path)\n",
    "\n",
    "sampled_noise = torch.randn(\n",
    "    [1, 21, 16, 60, 104], device=\"cuda\", dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "os.makedirs(args.output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3fc5b8d-7839-4ea8-9ef1-53e09f183a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfc52bbcd6f4697b7a100fa46a7afbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for prompt_index in tqdm(range(len(dataset))):\n",
    "    prompts = [dataset[prompt_index]]\n",
    "\n",
    "    video = pipeline.inference(\n",
    "        noise=sampled_noise,\n",
    "        text_prompts=prompts\n",
    "    )[0].permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "    export_to_video(\n",
    "        video, os.path.join(args.output_folder, f\"output_{prompt_index:03d}.mp4\"), fps=16)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a35e8b7-072c-4d96-8e26-b3267f6ed0d4",
   "metadata": {},
   "source": [
    "from causvid.models.wan.my_custom_inference import MyCustomInferencePipeline\n",
    "\n",
    "custom_pipeline = MyCustomInferencePipeline(config, device=\"cuda\", original_pipeline=pipeline)\n",
    "print(dir(custom_pipeline))\n",
    "\n",
    "# for prompt_index in tqdm(range(len(dataset))):\n",
    "#     prompts = [dataset[prompt_index]]\n",
    "\n",
    "#     video = custom_pipeline.custom_inference(\n",
    "#         noise=sampled_noise,\n",
    "#         text_prompts=prompts\n",
    "#     )[0].permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "#     export_to_video(\n",
    "#         video, os.path.join(args.output_folder, f\"custom_output_{prompt_index:03d}.mp4\"), fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f9fd0e-990d-4924-9a7f-a762ab7da441",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'my_custom_inference'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcausvid\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwan\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmy_custom_inference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmy_custom_inference\u001b[39;00m\n\u001b[1;32m      3\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(my_custom_inference)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmy_custom_inference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MyCustomInferencePipeline\n\u001b[1;32m      6\u001b[0m custom_pipeline \u001b[38;5;241m=\u001b[39m MyCustomInferencePipeline(config, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, original_pipeline\u001b[38;5;241m=\u001b[39mpipeline)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt_index \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset))):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'my_custom_inference'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import causvid.models.wan.my_custom_inference as my_custom_inference\n",
    "importlib.reload(my_custom_inference)\n",
    "# from my_custom_inference import MyCustomInferencePipeline\n",
    "\n",
    "# custom_pipeline = MyCustomInferencePipeline(config, device=\"cuda\", original_pipeline=pipeline)\n",
    "# for prompt_index in tqdm(range(len(dataset))):\n",
    "#     prompts = [dataset[prompt_index]]\n",
    "\n",
    "#     video = custom_pipeline.custom_inference(\n",
    "#         noise=sampled_noise,\n",
    "#         text_prompts=prompts\n",
    "#     )[0].permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "#     export_to_video(\n",
    "#         video, os.path.join(args.output_folder, f\"custom_output_{prompt_index:03d}.mp4\"), fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5ac30-401d-4b71-8fff-1ba95bee6c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
